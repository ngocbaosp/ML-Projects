{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoMLProject01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "StxbZGOO2y3I"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngocbaosp/ML-Projects/blob/master/AutoMLProject01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StxbZGOO2y3I",
        "colab_type": "text"
      },
      "source": [
        "# Install AutoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BisgUVyh-3x",
        "colab_type": "code",
        "outputId": "327fcbc9-40fc-4f14-d1e8-4bf7a162040c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get install swig -y\n",
        "!pip install Cython numpy\n",
        "\n",
        "# sometimes you have to run the next command twice on colab\n",
        "# I haven't figured out why\n",
        "!pip install auto-sklearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 1s (1,288 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 131331 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n",
            "Collecting auto-sklearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/99/27caac4f6804be48722158e31c630e0737110581774df0615a36b21239aa/auto-sklearn-0.5.2.tar.gz (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (41.0.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.7)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29.12)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.0)\n",
            "Collecting scikit-learn<0.20,>=0.19 (from auto-sklearn)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/c8/8db4108aba5e2166cd2ea4eafa1a4b82f89240a1fa85733029cc2358ad1f/scikit_learn-0.19.2-cp36-cp36m-manylinux1_x86_64.whl (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 27.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost>=0.80 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.90)\n",
            "Collecting lockfile (from auto-sklearn)\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
            "Collecting liac-arff (from auto-sklearn)\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/35/fbc9217cfa91d98888b43e1a19c03a50d716108c58494c558c65e308f372/liac-arff-2.4.0.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.24.2)\n",
            "Collecting ConfigSpace<0.5,>=0.4.0 (from auto-sklearn)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/de/4e8e4f26332fc65404f52baa112defbf822b6738b60bfa6b2993f5c60933/ConfigSpace-0.4.10.tar.gz (882kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.0MB/s \n",
            "\u001b[?25hCollecting pynisher>=0.4.2 (from auto-sklearn)\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/21/c86c64c305da6d43fb89780d33cbc839c07736b71955a8bdb642a02b7538/pynisher-0.5.0.tar.gz\n",
            "Collecting pyrfr<0.8,>=0.7 (from auto-sklearn)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/c6/c555cfa3c7d0078dded091d4901ed52344bbb925077aa70b871faf35fd58/pyrfr-0.7.4.tar.gz (291kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 42.5MB/s \n",
            "\u001b[?25hCollecting smac==0.8 (from auto-sklearn)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/ab/2b0a6fb00bd76e2415a04dcca453ad0b0db9b4218b02401306ff2bc6135d/smac-0.8.0.tar.gz (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2.5.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (3.7.4)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2->auto-sklearn) (0.14)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.12.0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.8.5)\n",
            "Collecting sphinx_rtd_theme (from smac==0.8->auto-sklearn)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/b4/4df37087a1d36755e3a3bfd2a30263f358d2dea21938240fa02313d45f51/sphinx_rtd_theme-0.4.3-py2.py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 24.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.1.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.7.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.9.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (19.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.21.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac==0.8->auto-sklearn) (1.1.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (1.24.3)\n",
            "Building wheels for collected packages: auto-sklearn, liac-arff, ConfigSpace, pynisher, pyrfr, smac\n",
            "  Building wheel for auto-sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/21/43/182fed664b6474f88600c110c4ebd254d6256ba59175cef3fd\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/6a/e7/529dc54d76ecede4346164a09ae3168df358945612710f5203\n",
            "  Building wheel for ConfigSpace (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/83/cb/28dd42bac69c8867d485138030daa83841c7f84afe68b2fdf7\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/2a/c4/ec3abc8a2f786ef9786ea8fe6ff629a4e54812a3f98cc41b47\n",
            "  Building wheel for pyrfr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/98/fd/b1d53cab6d5ed836980777d9733d7e549d82a727650eed6f6d\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/52/83/d2d66a840968025d072ddb1cd776fdc5eb5e337e1cc887bc3f\n",
            "Successfully built auto-sklearn liac-arff ConfigSpace pynisher pyrfr smac\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-learn, lockfile, liac-arff, ConfigSpace, pynisher, pyrfr, sphinx-rtd-theme, smac, auto-sklearn\n",
            "  Found existing installation: scikit-learn 0.21.2\n",
            "    Uninstalling scikit-learn-0.21.2:\n",
            "      Successfully uninstalled scikit-learn-0.21.2\n",
            "Successfully installed ConfigSpace-0.4.10 auto-sklearn-0.5.2 liac-arff-2.4.0 lockfile-0.12.2 pynisher-0.5.0 pyrfr-0.7.4 scikit-learn-0.19.2 smac-0.8.0 sphinx-rtd-theme-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Z7JRDni3Ms",
        "colab_type": "code",
        "outputId": "d7a609d3-4e7f-4e6a-d8ac-8e98fead1b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "!pip install auto-sklearn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.0)\n",
            "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.2)\n",
            "Requirement already satisfied: pynisher>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.24.2)\n",
            "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.2)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.4.10)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.16.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (41.0.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: pyrfr<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.4)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29.12)\n",
            "Requirement already satisfied: xgboost>=0.80 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.90)\n",
            "Requirement already satisfied: smac==0.8 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.8.0)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2->auto-sklearn) (0.14)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2.5.3)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (3.7.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (0.4.3)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (19.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.9.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.10.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.7.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.21.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac==0.8->auto-sklearn) (1.1.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw9o5GpGi7e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.model_selection\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "\n",
        "# Load data\n",
        "X, y = sklearn.datasets.load_digits(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "        sklearn.model_selection.train_test_split(X, y, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3zsYPyooEVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE4j6toFjO",
        "colab_type": "code",
        "outputId": "4d7123e2-39fb-486b-cca2-1e91328e031f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import autosklearn.classification\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
            "  from numpy.core.umath_tests import inner1d\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVxpdnVXjA-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d73769c2-bdd1-4761-de18-56be93875412"
      },
      "source": [
        "\n",
        "# configure auto-sklearn\n",
        "automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "          time_left_for_this_task=120, # run auto-sklearn for at most 2min\n",
        "          per_run_time_limit=30, # spend at most 30 sec for each model training\n",
        "          )\n",
        "\n",
        "# train model(s)\n",
        "automl.fit(X_train, y_train)\n",
        "\n",
        "# evaluate\n",
        "y_hat = automl.predict(X_test)\n",
        "test_acc = sklearn.metrics.accuracy_score(y_test, y_hat)\n",
        "print(\"Test Accuracy score {0}\".format(test_acc))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2019-07-29 19:46:10,678:EnsembleBuilder(1):d74860caaa557f473ce23908ff7ba369] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-29 19:46:10,696:EnsembleBuilder(1):d74860caaa557f473ce23908ff7ba369] No models better than random - using Dummy Score!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "Process pynisher function call:\n",
            "Process pynisher function call:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n",
            "    return_value = ((func(*args, **kwargs), 0))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/__init__.py\", line 30, in fit_predict_try_except_decorator\n",
            "    return ta(queue=queue, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n",
            "    return_value = ((func(*args, **kwargs), 0))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/ensemble_builder.py\", line 234, in main\n",
            "    time.sleep(self.sleep_duration)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py\", line 648, in eval_holdout\n",
            "    evaluator.fit_predict_and_loss(iterative=iterative)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py\", line 160, in fit_predict_and_loss\n",
            "    i, train_indices=train_split, test_indices=test_split\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py\", line 406, in _partial_fit_and_predict\n",
            "    self.Y_train[train_indices])\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/abstract_evaluator.py\", line 481, in _fit_and_suppress_warnings\n",
            "    model.fit(X, y)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/base.py\", line 93, in fit\n",
            "    self.fit_estimator(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/base.py\", line 110, in fit_estimator\n",
            "    self._final_estimator.fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/components/base.py\", line 402, in fit\n",
            "    return self.choice.fit(X, y, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/components/base.py\", line 163, in fit\n",
            "    self.iterative_fit(X, y, n_iter=n_iter, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/components/classification/gradient_boosting.py\", line 90, in iterative_fit\n",
            "    self.estimator.fit(X, y, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py\", line 1034, in fit\n",
            "    begin_at_stage, monitor, X_idx_sorted)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py\", line 1089, in _fit_stages\n",
            "    X_csc, X_csr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py\", line 798, in _fit_stage\n",
            "    self.learning_rate, k=k)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py\", line 249, in update_terminal_regions\n",
            "    y_pred[:, k], sample_weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py\", line 572, in _update_terminal_region\n",
            "    numerator = np.sum(sample_weight * residual)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 2076, in sum\n",
            "    initial=initial)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
            "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "KeyboardInterrupt\n",
            "Process pynisher function call:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n",
            "    return_value = ((func(*args, **kwargs), 0))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/__init__.py\", line 30, in fit_predict_try_except_decorator\n",
            "    return ta(queue=queue, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py\", line 648, in eval_holdout\n",
            "    evaluator.fit_predict_and_loss(iterative=iterative)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py\", line 160, in fit_predict_and_loss\n",
            "    i, train_indices=train_split, test_indices=test_split\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py\", line 406, in _partial_fit_and_predict\n",
            "    self.Y_train[train_indices])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/abstract_evaluator.py\", line 481, in _fit_and_suppress_warnings\n",
            "    model.fit(X, y)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/base.py\", line 93, in fit\n",
            "    self.fit_estimator(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/base.py\", line 110, in fit_estimator\n",
            "    self._final_estimator.fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/components/base.py\", line 402, in fit\n",
            "    return self.choice.fit(X, y, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/components/base.py\", line 163, in fit\n",
            "    self.iterative_fit(X, y, n_iter=n_iter, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/autosklearn/pipeline/components/classification/gradient_boosting.py\", line 90, in iterative_fit\n",
            "    self.estimator.fit(X, y, sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py\", line 1034, in fit\n",
            "    begin_at_stage, monitor, X_idx_sorted)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py\", line 1089, in _fit_stages\n",
            "    X_csc, X_csr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/gradient_boosting.py\", line 788, in _fit_stage\n",
            "    check_input=False, X_idx_sorted=X_idx_sorted)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\", line 1124, in fit\n",
            "    X_idx_sorted=X_idx_sorted)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\", line 362, in fit\n",
            "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
            "KeyboardInterrupt\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "['/tmp/autosklearn_tmp_132_977/.auto-sklearn/ensembles/1.0000000000.ensemble', '/tmp/autosklearn_tmp_132_977/.auto-sklearn/ensembles/1.0000000001.ensemble', '/tmp/autosklearn_tmp_132_977/.auto-sklearn/ensembles/1.0000000002.ensemble', '/tmp/autosklearn_tmp_132_977/.auto-sklearn/ensembles/1.0000000003.ensemble']\n",
            "Test Accuracy score 0.9933333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X89LTFhoI2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "automl.sprint_statistics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yukJU3_roQjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "automl.show_models()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmixqkcMoav8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "automl.cv_results_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GjDTVskomp1",
        "colab_type": "text"
      },
      "source": [
        "# AutoML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eWSIgFWo8O2",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a59x2kHcpQv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXK2-zGSpCxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% md\n",
        "#### MyPCA\n",
        "#%%\n",
        "def myPCA(data,n):\n",
        "    pca = PCA(n_components=n)\n",
        "    pca.fit(data)\n",
        "    df = pca.transform(data)\n",
        "    PCA_Data = pd.DataFrame(df)\n",
        "    return PCA_Data\n",
        "\n",
        "#%% md\n",
        "#### myNormalize\n",
        "#%%\n",
        "def myNormalize(data):\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    Normalized_Data = min_max_scaler.fit_transform(data)\n",
        "    Normalized_Data = pd.DataFrame(Normalized_Data)\n",
        "    return Normalized_Data\n",
        "\n",
        "#%% md\n",
        "#### myEncode\n",
        "#%%\n",
        "def myEncode(data,col): \n",
        "    NewData_Encode = data.copy()\n",
        "    NewData_Encode = pd.get_dummies(NewData_Encode, columns=col, prefix = col)\n",
        "    return NewData_Encode\n",
        "\n",
        "\n",
        "#%% md\n",
        "#### myCleanAndTransformData\n",
        "#%%\n",
        "def myCleanAndTransformData(data):\n",
        "    \n",
        "    #Drop null rows\n",
        "    NewData = data.dropna()\n",
        "    #Remove unknown ata\n",
        "    NewData = NewData[NewData['episodes']!='Unknown']\n",
        "    #Add a new column rating class \n",
        "    NewData['Class']=1\n",
        "    # 1: High\n",
        "    # or 0: Low based on rating\n",
        "    NewData.loc[NewData['rating'] >= NewData['rating'].mean(), 'Class'] = 1\n",
        "    NewData.loc[NewData['rating'] < NewData['rating'].mean(), 'Class'] = 0\n",
        "    \n",
        "    #Split genre values into rows\n",
        "    NewData = pd.DataFrame(NewData.genre.str.split(',').tolist(), index=[NewData.anime_id,NewData.type,NewData.episodes,NewData.rating,NewData.members,NewData.Class]).stack()\n",
        "    NewData = NewData.reset_index([0,'anime_id','type','episodes','rating','members','Class'])\n",
        "    NewData.columns=['anime_id','type','episodes','rating','members','Class','genre']\n",
        "    \n",
        "    #Encode type feature: 6 unique values\n",
        "    NewData = myEncode(NewData,['type'])\n",
        " \n",
        "    #Encode genre feature: 82 unique values\n",
        "    NewData = myEncode(NewData,['genre'])\n",
        " \n",
        "     #Drop anmie_id,rating,Class\n",
        "    NewData = NewData.drop(['rating'],axis=1)\n",
        "    NewData = NewData.drop(columns=['anime_id'])\n",
        "    NewData = NewData.drop(columns=['episodes'])  \n",
        "    \n",
        "    return NewData\n",
        "\n",
        "\n",
        "#%% md\n",
        "#### mySplitData\n",
        "#%%\n",
        "def mySplitData(X_Data,Y_Data,test_size,random_state):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_Data, Y_Data, test_size=test_size, random_state=random_state)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def mySplitDataByTrainSize(X_Data,Y_Data,train_size,random_state):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_Data, Y_Data, train_size=train_size, random_state=random_state)\n",
        "    X_train, X_test, y_train, y_test = mySplitData(X_train,y_train,0.33,random_state)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWwslp1EpaUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bbc6631e-d9e7-4cc5-b5ea-996955e41ad2"
      },
      "source": [
        "#%% md\n",
        "# Load data from files\n",
        "#%%\n",
        "RawData = pd.read_csv('anime.csv')\n",
        "RawData.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anime_id</th>\n",
              "      <th>name</th>\n",
              "      <th>genre</th>\n",
              "      <th>type</th>\n",
              "      <th>episodes</th>\n",
              "      <th>rating</th>\n",
              "      <th>members</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32281</td>\n",
              "      <td>Kimi no Na wa.</td>\n",
              "      <td>Drama, Romance, School, Supernatural</td>\n",
              "      <td>Movie</td>\n",
              "      <td>1</td>\n",
              "      <td>9.37</td>\n",
              "      <td>200630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5114</td>\n",
              "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
              "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
              "      <td>TV</td>\n",
              "      <td>64</td>\n",
              "      <td>9.26</td>\n",
              "      <td>793665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28977</td>\n",
              "      <td>Gintama°</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>TV</td>\n",
              "      <td>51</td>\n",
              "      <td>9.25</td>\n",
              "      <td>114262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9253</td>\n",
              "      <td>Steins;Gate</td>\n",
              "      <td>Sci-Fi, Thriller</td>\n",
              "      <td>TV</td>\n",
              "      <td>24</td>\n",
              "      <td>9.17</td>\n",
              "      <td>673572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9969</td>\n",
              "      <td>Gintama&amp;#039;</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>TV</td>\n",
              "      <td>51</td>\n",
              "      <td>9.16</td>\n",
              "      <td>151266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   anime_id                              name  ... rating members\n",
              "0     32281                    Kimi no Na wa.  ...   9.37  200630\n",
              "1      5114  Fullmetal Alchemist: Brotherhood  ...   9.26  793665\n",
              "2     28977                          Gintama°  ...   9.25  114262\n",
              "3      9253                       Steins;Gate  ...   9.17  673572\n",
              "4      9969                     Gintama&#039;  ...   9.16  151266\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwC0YFqhptN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b28792a5-aa2c-47ec-ea4a-9a0b24073f87"
      },
      "source": [
        "#%% md\n",
        "#### Clean and Transform Data\n",
        "#%%\n",
        "Cleaned_Data = myCleanAndTransformData(RawData)\n",
        "Y_Data = Cleaned_Data['Class']\n",
        "X_Data = Cleaned_Data.drop(columns=['Class'])\n",
        "\n",
        "#%% md\n",
        "#### Normalize  Data\n",
        "#%%\n",
        "Normalized_Data = myNormalize(X_Data)\n",
        "#%% md\n",
        "#### PCA\n",
        "#%%\n",
        "n_components=40\n",
        "PCA_Data = myPCA(Normalized_Data,n_components)\n",
        "PCA_Data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.311391</td>\n",
              "      <td>0.786561</td>\n",
              "      <td>-0.420790</td>\n",
              "      <td>0.005234</td>\n",
              "      <td>-0.078663</td>\n",
              "      <td>-0.049646</td>\n",
              "      <td>-0.062640</td>\n",
              "      <td>0.007159</td>\n",
              "      <td>-0.075350</td>\n",
              "      <td>-0.030938</td>\n",
              "      <td>0.086247</td>\n",
              "      <td>-0.139425</td>\n",
              "      <td>-0.157022</td>\n",
              "      <td>0.028365</td>\n",
              "      <td>-0.081108</td>\n",
              "      <td>-0.232703</td>\n",
              "      <td>-0.299120</td>\n",
              "      <td>0.804699</td>\n",
              "      <td>-0.258797</td>\n",
              "      <td>-0.007687</td>\n",
              "      <td>-0.094831</td>\n",
              "      <td>-0.108054</td>\n",
              "      <td>-0.062475</td>\n",
              "      <td>0.025711</td>\n",
              "      <td>0.003369</td>\n",
              "      <td>-0.024983</td>\n",
              "      <td>-0.033523</td>\n",
              "      <td>-0.004934</td>\n",
              "      <td>-0.011702</td>\n",
              "      <td>-0.006729</td>\n",
              "      <td>-0.011742</td>\n",
              "      <td>-0.014507</td>\n",
              "      <td>0.009433</td>\n",
              "      <td>-0.010485</td>\n",
              "      <td>-0.008221</td>\n",
              "      <td>-0.004127</td>\n",
              "      <td>0.005306</td>\n",
              "      <td>-0.012853</td>\n",
              "      <td>-0.006433</td>\n",
              "      <td>-0.008562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.284662</td>\n",
              "      <td>0.764035</td>\n",
              "      <td>-0.411982</td>\n",
              "      <td>-0.010872</td>\n",
              "      <td>-0.110067</td>\n",
              "      <td>-0.087035</td>\n",
              "      <td>-0.096786</td>\n",
              "      <td>0.054585</td>\n",
              "      <td>-0.179466</td>\n",
              "      <td>-0.045549</td>\n",
              "      <td>0.764383</td>\n",
              "      <td>0.581495</td>\n",
              "      <td>0.033808</td>\n",
              "      <td>-0.066725</td>\n",
              "      <td>0.030970</td>\n",
              "      <td>0.068166</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>-0.031955</td>\n",
              "      <td>-0.043632</td>\n",
              "      <td>0.008161</td>\n",
              "      <td>-0.027471</td>\n",
              "      <td>-0.040192</td>\n",
              "      <td>-0.033360</td>\n",
              "      <td>0.004737</td>\n",
              "      <td>0.006610</td>\n",
              "      <td>-0.016134</td>\n",
              "      <td>-0.028708</td>\n",
              "      <td>-0.009434</td>\n",
              "      <td>-0.005291</td>\n",
              "      <td>-0.004034</td>\n",
              "      <td>-0.007216</td>\n",
              "      <td>-0.013007</td>\n",
              "      <td>0.006323</td>\n",
              "      <td>-0.011350</td>\n",
              "      <td>-0.008301</td>\n",
              "      <td>-0.001372</td>\n",
              "      <td>0.008429</td>\n",
              "      <td>-0.012475</td>\n",
              "      <td>-0.008168</td>\n",
              "      <td>-0.009003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.284659</td>\n",
              "      <td>0.767955</td>\n",
              "      <td>-0.395541</td>\n",
              "      <td>-0.007615</td>\n",
              "      <td>-0.091869</td>\n",
              "      <td>-0.059768</td>\n",
              "      <td>-0.062093</td>\n",
              "      <td>0.036484</td>\n",
              "      <td>-0.086830</td>\n",
              "      <td>-0.024722</td>\n",
              "      <td>0.092133</td>\n",
              "      <td>-0.282600</td>\n",
              "      <td>-0.452072</td>\n",
              "      <td>-0.568979</td>\n",
              "      <td>0.527521</td>\n",
              "      <td>0.286982</td>\n",
              "      <td>0.035407</td>\n",
              "      <td>-0.060924</td>\n",
              "      <td>-0.105755</td>\n",
              "      <td>-0.014484</td>\n",
              "      <td>-0.031113</td>\n",
              "      <td>-0.062844</td>\n",
              "      <td>-0.045536</td>\n",
              "      <td>0.012570</td>\n",
              "      <td>0.004928</td>\n",
              "      <td>-0.021738</td>\n",
              "      <td>-0.033730</td>\n",
              "      <td>-0.011367</td>\n",
              "      <td>-0.009055</td>\n",
              "      <td>-0.006117</td>\n",
              "      <td>-0.009460</td>\n",
              "      <td>-0.014713</td>\n",
              "      <td>0.006533</td>\n",
              "      <td>-0.012725</td>\n",
              "      <td>-0.009930</td>\n",
              "      <td>-0.005330</td>\n",
              "      <td>0.006565</td>\n",
              "      <td>-0.014448</td>\n",
              "      <td>-0.012789</td>\n",
              "      <td>-0.008875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.291422</td>\n",
              "      <td>0.777222</td>\n",
              "      <td>-0.408286</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>-0.080828</td>\n",
              "      <td>-0.049801</td>\n",
              "      <td>-0.056895</td>\n",
              "      <td>0.019128</td>\n",
              "      <td>-0.070776</td>\n",
              "      <td>-0.027971</td>\n",
              "      <td>0.078002</td>\n",
              "      <td>-0.143408</td>\n",
              "      <td>-0.122654</td>\n",
              "      <td>-0.013020</td>\n",
              "      <td>-0.109531</td>\n",
              "      <td>-0.389553</td>\n",
              "      <td>-0.602799</td>\n",
              "      <td>-0.563673</td>\n",
              "      <td>-0.290784</td>\n",
              "      <td>-0.050571</td>\n",
              "      <td>-0.053018</td>\n",
              "      <td>-0.099431</td>\n",
              "      <td>-0.061850</td>\n",
              "      <td>0.024372</td>\n",
              "      <td>0.000898</td>\n",
              "      <td>-0.027266</td>\n",
              "      <td>-0.035613</td>\n",
              "      <td>-0.010752</td>\n",
              "      <td>-0.013571</td>\n",
              "      <td>-0.007647</td>\n",
              "      <td>-0.012239</td>\n",
              "      <td>-0.015412</td>\n",
              "      <td>0.007587</td>\n",
              "      <td>-0.011299</td>\n",
              "      <td>-0.009393</td>\n",
              "      <td>-0.007804</td>\n",
              "      <td>0.004307</td>\n",
              "      <td>-0.014111</td>\n",
              "      <td>-0.011770</td>\n",
              "      <td>-0.010724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.731807</td>\n",
              "      <td>-0.153182</td>\n",
              "      <td>-0.102195</td>\n",
              "      <td>-0.458238</td>\n",
              "      <td>0.816873</td>\n",
              "      <td>0.046188</td>\n",
              "      <td>0.015792</td>\n",
              "      <td>-0.064744</td>\n",
              "      <td>0.014353</td>\n",
              "      <td>-0.005002</td>\n",
              "      <td>0.000638</td>\n",
              "      <td>0.017529</td>\n",
              "      <td>-0.007235</td>\n",
              "      <td>0.008140</td>\n",
              "      <td>0.015745</td>\n",
              "      <td>-0.003273</td>\n",
              "      <td>-0.012159</td>\n",
              "      <td>-0.006524</td>\n",
              "      <td>-0.014003</td>\n",
              "      <td>0.005176</td>\n",
              "      <td>-0.027948</td>\n",
              "      <td>-0.018706</td>\n",
              "      <td>-0.009773</td>\n",
              "      <td>-0.001108</td>\n",
              "      <td>0.018647</td>\n",
              "      <td>0.005479</td>\n",
              "      <td>-0.018145</td>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.021768</td>\n",
              "      <td>0.001473</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>-0.013188</td>\n",
              "      <td>0.019870</td>\n",
              "      <td>-0.014564</td>\n",
              "      <td>-0.007068</td>\n",
              "      <td>0.027246</td>\n",
              "      <td>0.025586</td>\n",
              "      <td>-0.017256</td>\n",
              "      <td>0.000591</td>\n",
              "      <td>0.043840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        37        38        39\n",
              "0 -0.311391  0.786561 -0.420790  ... -0.012853 -0.006433 -0.008562\n",
              "1 -0.284662  0.764035 -0.411982  ... -0.012475 -0.008168 -0.009003\n",
              "2 -0.284659  0.767955 -0.395541  ... -0.014448 -0.012789 -0.008875\n",
              "3 -0.291422  0.777222 -0.408286  ... -0.014111 -0.011770 -0.010724\n",
              "4  0.731807 -0.153182 -0.102195  ... -0.017256  0.000591  0.043840\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T50hJ8mq2AZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "85f3d810-10c5-4d9e-c03d-cbac1724d9f2"
      },
      "source": [
        "#%% md\n",
        "####----------------------------------------------------------------\n",
        "#### Split  PCA_Data\n",
        "####----------------------------------------------------------------\n",
        "#%%\n",
        "PCA_X_train, PCA_X_test, PCA_y_train, PCA_y_test  = mySplitData(PCA_Data,Y_Data,0.33,42)\n",
        "\n",
        "PCA_X_train.head()\n",
        "#%%\n",
        "PCA_X_test.head()\n",
        "#%%\n",
        "PCA_y_train.head()\n",
        "#%%\n",
        "PCA_y_test.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22373    0\n",
              "10508    1\n",
              "11570    1\n",
              "22262    0\n",
              "734      1\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyaIjFEzq9_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uesuJDbrHRU",
        "colab_type": "text"
      },
      "source": [
        "## **Train and Test Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nn4NvY4rM6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7c6d7a04-f864-42dd-c0fd-8ee86ae0b1cd"
      },
      "source": [
        "# configure auto-sklearn\n",
        "anmie_automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "          time_left_for_this_task=120, # run auto-sklearn for at most 2min\n",
        "          per_run_time_limit=30, # spend at most 30 sec for each model training\n",
        "          include_preprocessors=[\"no_preprocessing\"]\n",
        "          )\n",
        "\n",
        "# train model(s)\n",
        "anmie_automl.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "PCA_y_predicted = anmie_automl.predict(PCA_X_test)\n",
        "test_acc = sklearn.metrics.accuracy_score(PCA_y_test, PCA_y_predicted)\n",
        "print(\"Test Accuracy score {0}\".format(test_acc))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2019-07-29 20:08:53,690:EnsembleBuilder(1):71f0d138d36d804a44a29370a5721519] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-29 20:08:53,704:EnsembleBuilder(1):71f0d138d36d804a44a29370a5721519] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-29 20:08:55,709:EnsembleBuilder(1):71f0d138d36d804a44a29370a5721519] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-29 20:08:57,716:EnsembleBuilder(1):71f0d138d36d804a44a29370a5721519] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-29 20:08:59,722:EnsembleBuilder(1):71f0d138d36d804a44a29370a5721519] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-29 20:09:01,737:EnsembleBuilder(1):71f0d138d36d804a44a29370a5721519] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-29 20:09:03,752:EnsembleBuilder(1):71f0d138d36d804a44a29370a5721519] No models better than random - using Dummy Score!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2019-07-29 20:10:38,380:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
            "[WARNING] [2019-07-29 20:10:38,380:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
            "1\n",
            "['/tmp/autosklearn_tmp_132_195/.auto-sklearn/ensembles/1.0000000000.ensemble', '/tmp/autosklearn_tmp_132_195/.auto-sklearn/ensembles/1.0000000001.ensemble', '/tmp/autosklearn_tmp_132_195/.auto-sklearn/ensembles/1.0000000002.ensemble']\n",
            "Test Accuracy score 0.7654299733149694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEjZqYPpswxw",
        "colab_type": "text"
      },
      "source": [
        "## Inspecting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47ATUCSls-cx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ac9221e7-d68b-4dd3-ea09-2074b7421c48"
      },
      "source": [
        "automl.sprint_statistics()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'auto-sklearn results:\\n  Dataset name: d74860caaa557f473ce23908ff7ba369\\n  Metric: accuracy\\n  Best validation score: 0.991011\\n  Number of target algorithm runs: 26\\n  Number of successful target algorithm runs: 22\\n  Number of crashed target algorithm runs: 2\\n  Number of target algorithms that exceeded the time limit: 2\\n  Number of target algorithms that exceeded the memory limit: 0\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW2h1ROVtCWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "06dd8475-00f4-4024-9c17-b09cbbbe955f"
      },
      "source": [
        "anmie_automl.show_models()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[(0.640000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01},\\ndataset_properties={\\n  'task': 1,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.360000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gaussian_nb', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'robust_scaler', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'rescaling:robust_scaler:q_max': 0.8245132980938538, 'rescaling:robust_scaler:q_min': 0.08947420373097192, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00034835629696198427},\\ndataset_properties={\\n  'task': 1,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'classification',\\n  'signed': False})),\\n]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVYIHHlotGEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bc2bb5e-e277-4d11-afb0-acb6f2af621c"
      },
      "source": [
        "anmie_automl.cv_results_"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([10.36883998, 30.03817606, 30.03083205, 30.03898716,  0.47739506,\n",
              "         3.01575017]),\n",
              " 'mean_test_score': array([0.74174483, 0.        , 0.        , 0.        , 0.65758705,\n",
              "        0.        ]),\n",
              " 'param_balancing:strategy': masked_array(data=['none', 'weighting', 'none', 'none', 'weighting',\n",
              "                    'none'],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U9'),\n",
              " 'param_categorical_encoding:__choice__': masked_array(data=['one_hot_encoding', 'one_hot_encoding',\n",
              "                    'one_hot_encoding', 'one_hot_encoding',\n",
              "                    'one_hot_encoding', 'one_hot_encoding'],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U16'),\n",
              " 'param_categorical_encoding:one_hot_encoding:minimum_fraction': masked_array(data=[0.01, 0.010000000000000004, --, --,\n",
              "                    0.00034835629696198427, 0.00012586572428922356],\n",
              "              mask=[False, False,  True,  True, False, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_categorical_encoding:one_hot_encoding:use_minimum_fraction': masked_array(data=['True', 'True', 'False', 'False', 'True', 'True'],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U5'),\n",
              " 'param_classifier:__choice__': masked_array(data=['random_forest', 'gradient_boosting', 'libsvm_svc',\n",
              "                    'random_forest', 'gaussian_nb', 'random_forest'],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U17'),\n",
              " 'param_classifier:adaboost:algorithm': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:adaboost:learning_rate': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:adaboost:max_depth': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:adaboost:n_estimators': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:bernoulli_nb:alpha': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:bernoulli_nb:fit_prior': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:criterion': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:max_depth_factor': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:max_features': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:min_samples_leaf': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:min_samples_split': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:bootstrap': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:criterion': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:max_depth': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:max_features': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:min_samples_split': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:n_estimators': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:gradient_boosting:criterion': masked_array(data=[--, 'mse', --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:gradient_boosting:learning_rate': masked_array(data=[--, 0.051832615669195795, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:loss': masked_array(data=[--, 'deviance', --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:gradient_boosting:max_depth': masked_array(data=[--, 6.0, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:max_features': masked_array(data=[--, 0.8807456180216267, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:max_leaf_nodes': masked_array(data=[--, 'None', --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:gradient_boosting:min_impurity_decrease': masked_array(data=[--, 0.0, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:min_samples_leaf': masked_array(data=[--, 7.0, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:min_samples_split': masked_array(data=[--, 19.0, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:min_weight_fraction_leaf': masked_array(data=[--, 0.0, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:n_estimators': masked_array(data=[--, 366.0, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:subsample': masked_array(data=[--, 0.7314831276137047, --, --, --, --],\n",
              "              mask=[ True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:k_nearest_neighbors:n_neighbors': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:k_nearest_neighbors:p': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:k_nearest_neighbors:weights': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:lda:n_components': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:lda:shrinkage': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:lda:shrinkage_factor': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:lda:tol': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:C': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:dual': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:fit_intercept': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:intercept_scaling': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:loss': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:multi_class': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:penalty': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:tol': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:libsvm_svc:C': masked_array(data=[--, --, 6.342897164595882, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:libsvm_svc:coef0': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:libsvm_svc:degree': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:libsvm_svc:gamma': masked_array(data=[--, --, 0.2229870623330047, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:libsvm_svc:kernel': masked_array(data=[--, --, 'rbf', --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:libsvm_svc:max_iter': masked_array(data=[--, --, -1.0, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:libsvm_svc:shrinking': masked_array(data=[--, --, 'False', --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:libsvm_svc:tol': masked_array(data=[--, --, 2.006345264381097e-05, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:multinomial_nb:alpha': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:multinomial_nb:fit_prior': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:C': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:average': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:fit_intercept': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:loss': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:tol': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:qda:reg_param': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:random_forest:bootstrap': masked_array(data=['True', --, --, 'True', --, 'True'],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U4'),\n",
              " 'param_classifier:random_forest:criterion': masked_array(data=['gini', --, --, 'gini', --, 'gini'],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U4'),\n",
              " 'param_classifier:random_forest:max_depth': masked_array(data=['None', --, --, 'None', --, 'None'],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U4'),\n",
              " 'param_classifier:random_forest:max_features': masked_array(data=[0.5, --, --, 0.9260795160807372, --,\n",
              "                    0.5240592829918601],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:max_leaf_nodes': masked_array(data=['None', --, --, 'None', --, 'None'],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U4'),\n",
              " 'param_classifier:random_forest:min_impurity_decrease': masked_array(data=[0.0, --, --, 0.0, --, 0.0],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:min_samples_leaf': masked_array(data=[1.0, --, --, 17.0, --, 10.0],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:min_samples_split': masked_array(data=[2.0, --, --, 7.0, --, 16.0],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, --, --, 0.0, --, 0.0],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:n_estimators': masked_array(data=[100.0, --, --, 100.0, --, 100.0],\n",
              "              mask=[False,  True,  True, False,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:sgd:alpha': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:average': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:epsilon': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:eta0': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:fit_intercept': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:l1_ratio': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:learning_rate': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:loss': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:penalty': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:power_t': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:tol': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:base_score': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:booster': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:colsample_bylevel': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:colsample_bytree': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:gamma': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:learning_rate': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:max_delta_step': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:max_depth': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:min_child_weight': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:n_estimators': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:normalize_type': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:rate_drop': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:reg_alpha': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:reg_lambda': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:sample_type': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:scale_pos_weight': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:subsample': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_imputation:strategy': masked_array(data=['mean', 'mean', 'most_frequent', 'mean', 'mean',\n",
              "                    'mean'],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U13'),\n",
              " 'param_preprocessor:__choice__': masked_array(data=['no_preprocessing', 'no_preprocessing',\n",
              "                    'no_preprocessing', 'no_preprocessing',\n",
              "                    'no_preprocessing', 'no_preprocessing'],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U16'),\n",
              " 'param_rescaling:__choice__': masked_array(data=['standardize', 'standardize', 'standardize', 'minmax',\n",
              "                    'robust_scaler', 'normalize'],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U13'),\n",
              " 'param_rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_rescaling:robust_scaler:q_max': masked_array(data=[--, --, --, --, 0.8245132980938538, --],\n",
              "              mask=[ True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_rescaling:robust_scaler:q_min': masked_array(data=[--, --, --, --, 0.08947420373097192, --],\n",
              "              mask=[ True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'params': [{'balancing:strategy': 'none',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'random_forest',\n",
              "   'classifier:random_forest:bootstrap': 'True',\n",
              "   'classifier:random_forest:criterion': 'gini',\n",
              "   'classifier:random_forest:max_depth': 'None',\n",
              "   'classifier:random_forest:max_features': 0.5,\n",
              "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
              "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
              "   'classifier:random_forest:min_samples_leaf': 1,\n",
              "   'classifier:random_forest:min_samples_split': 2,\n",
              "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:random_forest:n_estimators': 100,\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'standardize'},\n",
              "  {'balancing:strategy': 'weighting',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'gradient_boosting',\n",
              "   'classifier:gradient_boosting:criterion': 'mse',\n",
              "   'classifier:gradient_boosting:learning_rate': 0.051832615669195795,\n",
              "   'classifier:gradient_boosting:loss': 'deviance',\n",
              "   'classifier:gradient_boosting:max_depth': 6,\n",
              "   'classifier:gradient_boosting:max_features': 0.8807456180216267,\n",
              "   'classifier:gradient_boosting:max_leaf_nodes': 'None',\n",
              "   'classifier:gradient_boosting:min_impurity_decrease': 0.0,\n",
              "   'classifier:gradient_boosting:min_samples_leaf': 7,\n",
              "   'classifier:gradient_boosting:min_samples_split': 19,\n",
              "   'classifier:gradient_boosting:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:gradient_boosting:n_estimators': 366,\n",
              "   'classifier:gradient_boosting:subsample': 0.7314831276137047,\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'standardize'},\n",
              "  {'balancing:strategy': 'none',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False',\n",
              "   'classifier:__choice__': 'libsvm_svc',\n",
              "   'classifier:libsvm_svc:C': 6.342897164595882,\n",
              "   'classifier:libsvm_svc:gamma': 0.2229870623330047,\n",
              "   'classifier:libsvm_svc:kernel': 'rbf',\n",
              "   'classifier:libsvm_svc:max_iter': -1,\n",
              "   'classifier:libsvm_svc:shrinking': 'False',\n",
              "   'classifier:libsvm_svc:tol': 2.006345264381097e-05,\n",
              "   'imputation:strategy': 'most_frequent',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'standardize'},\n",
              "  {'balancing:strategy': 'none',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False',\n",
              "   'classifier:__choice__': 'random_forest',\n",
              "   'classifier:random_forest:bootstrap': 'True',\n",
              "   'classifier:random_forest:criterion': 'gini',\n",
              "   'classifier:random_forest:max_depth': 'None',\n",
              "   'classifier:random_forest:max_features': 0.9260795160807372,\n",
              "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
              "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
              "   'classifier:random_forest:min_samples_leaf': 17,\n",
              "   'classifier:random_forest:min_samples_split': 7,\n",
              "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:random_forest:n_estimators': 100,\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'minmax'},\n",
              "  {'balancing:strategy': 'weighting',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00034835629696198427,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'gaussian_nb',\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'robust_scaler',\n",
              "   'rescaling:robust_scaler:q_max': 0.8245132980938538,\n",
              "   'rescaling:robust_scaler:q_min': 0.08947420373097192},\n",
              "  {'balancing:strategy': 'none',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00012586572428922356,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'random_forest',\n",
              "   'classifier:random_forest:bootstrap': 'True',\n",
              "   'classifier:random_forest:criterion': 'gini',\n",
              "   'classifier:random_forest:max_depth': 'None',\n",
              "   'classifier:random_forest:max_features': 0.5240592829918601,\n",
              "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
              "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
              "   'classifier:random_forest:min_samples_leaf': 10,\n",
              "   'classifier:random_forest:min_samples_split': 16,\n",
              "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:random_forest:n_estimators': 100,\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'normalize'}],\n",
              " 'rank_test_scores': array([1, 3, 3, 3, 2, 3]),\n",
              " 'status': ['Success', 'Timeout', 'Timeout', 'Timeout', 'Success', 'Timeout']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhpbbHnV3b3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0nlmBEQR6Nd",
        "colab_type": "text"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuHZbULXSTfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c072386e-d77c-4c66-bb01-2b0259e091be"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=30)\n",
        "\n",
        "# train model(s)\n",
        "knn_m = knn.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "knn_test_acc = knn_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(knn_test_acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.7884996126366531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZcFpZiIR87D",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HJiVRVCXvKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca79ce50-77cd-49c8-ca03-73e35e7bc148"
      },
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "# Create a svm Classifier with PCA data\n",
        "svc = svm.SVC(C=1.0, gamma=0.1, kernel='rbf') # Linear Kernel\n",
        "\n",
        "# train model(s)\n",
        "svm_m = svc.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "svm_test_acc = svm_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(svm_test_acc))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.6978565894809331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WefgYsW4R_td",
        "colab_type": "text"
      },
      "source": [
        "# DT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmpigibbYm2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25e78fa6-3d6b-4402-c45f-148cf277710f"
      },
      "source": [
        "#Import svm model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Create a DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=0,max_depth=30,min_samples_leaf=20)\n",
        "\n",
        "\n",
        "# train model(s)\n",
        "dt_m = dt.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "dt_test_acc = dt_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(dt_test_acc))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.794525264698287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zntQsupZSB_O",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N_gyiFQaL-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6629eab6-fdb5-4442-e188-ea54ab4f3f8f"
      },
      "source": [
        "#Import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a Random Forest Classifier with original data\n",
        "rf = RandomForestClassifier(criterion ='gini', max_depth= 15, max_features= 'sqrt', min_samples_leaf=1, min_samples_split= 5, n_estimators= 300)\n",
        "\n",
        "\n",
        "# train model(s)\n",
        "rf_m = rf.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "rf_test_acc = rf_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(rf_test_acc))\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.7976241714728415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eToqzWdTSFFB",
        "colab_type": "text"
      },
      "source": [
        "# Neuron Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkdWo0y0h5PZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1302795-8541-4a89-825a-63670f98bb97"
      },
      "source": [
        "#Import svm model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Create a NN Classifier with PCA data\n",
        "nn = MLPClassifier(max_iter=500)\n",
        "\n",
        "# train model(s)\n",
        "nn_m = nn.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "nn_test_acc = nn_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(nn_test_acc))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.7011276577429629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z8eT3iobBY8",
        "colab_type": "text"
      },
      "source": [
        "# Comparision "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0yGI7PkbIpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "ee090e5d-33d7-463c-f37c-acd4f2873b20"
      },
      "source": [
        "from yellowbrick.classifier import ROCAUC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=0,max_depth=30,min_samples_leaf=20)\n",
        "classes = [\"Low\", \"High\"]\n",
        "# Instantiate the visualizer with the classification model\n",
        "visualizer = ROCAUC(dt,classes=classes)\n",
        "\n",
        "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
        "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "g = visualizer.poof()     "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFnCAYAAABU0WtaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wXnM5YYecEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "a252b05e-5ca0-460b-f8bc-ef2c73566f7b"
      },
      "source": [
        "clf = DecisionTreeClassifier(random_state=0,max_depth=30,min_samples_leaf=20)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "\n",
        "clf.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "dt_lm = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "dt_lm.fit(PCA_X_test, PCA_y_test)\n",
        "\n",
        "y_pred_dt = clf.predict_proba(PCA_X_test)[:, 1]\n",
        "fpr_dt, tpr_dt, _ = roc_curve(PCA_y_test, y_pred_dt)\n",
        "roc_auc = auc(fpr_dt, tpr_dt)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "\n",
        "\n",
        "#KNN \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=30)\n",
        "knn_m = knn.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "knn_lm = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "knn_lm.fit(PCA_X_test, PCA_y_test)\n",
        "\n",
        "y_pred_knn = knn.predict_proba(PCA_X_test)[:, 1]\n",
        "knn_fpr_dt, knn_tpr_dt, _ = roc_curve(PCA_y_test, y_pred_knn)\n",
        "knn_roc_auc = auc(knn_fpr_dt, knn_tpr_dt)\n",
        "\n",
        "\n",
        "plt.plot(fpr_dt, tpr_dt, label='ROC of DT (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot(knn_fpr_dt, knn_tpr_dt, label='ROC of KNN (AUC = %0.2f)' % knn_roc_auc)\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyllWO0npzLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}