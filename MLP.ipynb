{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "MLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngocbaosp/ML-Projects/blob/master/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5LN7YTd2D0Lf",
        "colab_type": "text"
      },
      "source": [
        "#### Course: Machine Learning \n",
        "#### Project: 01\n",
        "#### Team members\n",
        "#### + Mauro Travieso Pena\n",
        "#### + Quoc Huy Luong\n",
        "#### + Ngoc Bao Tran\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VpI8BtV0D0Lj",
        "colab_type": "text"
      },
      "source": [
        "## Multi-layer Perceptron Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5qNzmeXD0Lm",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "PlHthr6ND0Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Install library\n",
        "# !pip3 install -U yellowbrick\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j4DRSupPBH2x",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "# MyPCA\n",
        "\n",
        "def myPCA(data,n):\n",
        "    pca = PCA(n_components=n)\n",
        "    pca.fit(data)\n",
        "    df = pca.transform(data)\n",
        "    PCA_Data = pd.DataFrame(df)\n",
        "    return PCA_Data\n",
        "\n",
        "\n",
        "\n",
        "# myNormalize\n",
        "\n",
        "def myNormalize(data):\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    Normalized_Data = min_max_scaler.fit_transform(data)\n",
        "    Normalized_Data = pd.DataFrame(Normalized_Data)\n",
        "    return Normalized_Data\n",
        "\n",
        "\n",
        "\n",
        "# myEncode\n",
        "\n",
        "def myEncode(data,col): \n",
        "    NewData_Encode = data.copy()\n",
        "    NewData_Encode = pd.get_dummies(NewData_Encode, columns=col, prefix = col)\n",
        "    return NewData_Encode\n",
        "\n",
        "\n",
        "\n",
        "# myCleanAndTransformData\n",
        "\n",
        "\n",
        "def myCleanAndTransformData(data):\n",
        "    \n",
        "    #Drop null rows\n",
        "    NewData = data.dropna()\n",
        "    #Remove unknown ata\n",
        "    NewData = NewData[NewData['episodes']!='Unknown']\n",
        "    #Add a new column rating class \n",
        "    NewData['Class']=1\n",
        "    # 1: High\n",
        "    # or 0: Low based on rating\n",
        "    NewData.loc[NewData['rating'] >= NewData['rating'].mean(), 'Class'] = 1\n",
        "    NewData.loc[NewData['rating'] < NewData['rating'].mean(), 'Class'] = 0\n",
        "    \n",
        "    #Split genre values into rows\n",
        "    NewData = pd.DataFrame(NewData.genre.str.split(',').tolist(), index=[NewData.anime_id,NewData.type,NewData.episodes,NewData.rating,NewData.members,NewData.Class]).stack()\n",
        "    NewData = NewData.reset_index([0,'anime_id','type','episodes','rating','members','Class'])\n",
        "    NewData.columns=['anime_id','type','episodes','rating','members','Class','genre']\n",
        "    \n",
        "    #Encode type feature: 6 unique values\n",
        "    NewData = myEncode(NewData,['type'])\n",
        " \n",
        "    #Encode genre feature: 82 unique values\n",
        "    NewData = myEncode(NewData,['genre'])\n",
        " \n",
        "     #Drop anmie_id,rating,Class\n",
        "    NewData = NewData.drop(['rating'],axis=1)\n",
        "    NewData = NewData.drop(columns=['anime_id'])\n",
        "    #NewData = NewData.drop(columns=['Class'])  \n",
        "    \n",
        "    return NewData\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOzIDDPXD0L0",
        "colab_type": "text"
      },
      "source": [
        "### Load data from files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "GS4MmPT2D0L1",
        "colab_type": "code",
        "outputId": "62ee7219-e133-4dcd-d089-692ef519bd28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df = pd.read_csv('anime.csv')\n",
        "df.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anime_id</th>\n",
              "      <th>name</th>\n",
              "      <th>genre</th>\n",
              "      <th>type</th>\n",
              "      <th>episodes</th>\n",
              "      <th>rating</th>\n",
              "      <th>members</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32281</td>\n",
              "      <td>Kimi no Na wa.</td>\n",
              "      <td>Drama, Romance, School, Supernatural</td>\n",
              "      <td>Movie</td>\n",
              "      <td>1</td>\n",
              "      <td>9.37</td>\n",
              "      <td>200630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5114</td>\n",
              "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
              "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
              "      <td>TV</td>\n",
              "      <td>64</td>\n",
              "      <td>9.26</td>\n",
              "      <td>793665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28977</td>\n",
              "      <td>Gintama°</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>TV</td>\n",
              "      <td>51</td>\n",
              "      <td>9.25</td>\n",
              "      <td>114262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9253</td>\n",
              "      <td>Steins;Gate</td>\n",
              "      <td>Sci-Fi, Thriller</td>\n",
              "      <td>TV</td>\n",
              "      <td>24</td>\n",
              "      <td>9.17</td>\n",
              "      <td>673572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9969</td>\n",
              "      <td>Gintama&amp;#039;</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>TV</td>\n",
              "      <td>51</td>\n",
              "      <td>9.16</td>\n",
              "      <td>151266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   anime_id                              name  ... rating members\n",
              "0     32281                    Kimi no Na wa.  ...   9.37  200630\n",
              "1      5114  Fullmetal Alchemist: Brotherhood  ...   9.26  793665\n",
              "2     28977                          Gintama°  ...   9.25  114262\n",
              "3      9253                       Steins;Gate  ...   9.17  673572\n",
              "4      9969                     Gintama&#039;  ...   9.16  151266\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEMhGQJDD0L8",
        "colab_type": "text"
      },
      "source": [
        "### Clean and Transform Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "DsLvX_aDD0L9",
        "colab_type": "code",
        "outputId": "b4c2fddf-4e61-4264-b932-b578ef94ddcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "cleaned_data= myCleanAndTransformData(df)\n",
        "df_test = cleaned_data['Class']\n",
        "df_train = cleaned_data.drop(columns=['Class'])\n",
        "df_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>episodes</th>\n",
              "      <th>members</th>\n",
              "      <th>type_Movie</th>\n",
              "      <th>type_Music</th>\n",
              "      <th>type_ONA</th>\n",
              "      <th>type_OVA</th>\n",
              "      <th>type_Special</th>\n",
              "      <th>type_TV</th>\n",
              "      <th>genre_ Adventure</th>\n",
              "      <th>genre_ Cars</th>\n",
              "      <th>genre_ Comedy</th>\n",
              "      <th>genre_ Dementia</th>\n",
              "      <th>genre_ Demons</th>\n",
              "      <th>genre_ Drama</th>\n",
              "      <th>genre_ Ecchi</th>\n",
              "      <th>genre_ Fantasy</th>\n",
              "      <th>genre_ Game</th>\n",
              "      <th>genre_ Harem</th>\n",
              "      <th>genre_ Hentai</th>\n",
              "      <th>genre_ Historical</th>\n",
              "      <th>genre_ Horror</th>\n",
              "      <th>genre_ Josei</th>\n",
              "      <th>genre_ Kids</th>\n",
              "      <th>genre_ Magic</th>\n",
              "      <th>genre_ Martial Arts</th>\n",
              "      <th>genre_ Mecha</th>\n",
              "      <th>genre_ Military</th>\n",
              "      <th>genre_ Music</th>\n",
              "      <th>genre_ Mystery</th>\n",
              "      <th>genre_ Parody</th>\n",
              "      <th>genre_ Police</th>\n",
              "      <th>genre_ Psychological</th>\n",
              "      <th>genre_ Romance</th>\n",
              "      <th>genre_ Samurai</th>\n",
              "      <th>genre_ School</th>\n",
              "      <th>genre_ Sci-Fi</th>\n",
              "      <th>genre_ Seinen</th>\n",
              "      <th>genre_ Shoujo</th>\n",
              "      <th>genre_ Shoujo Ai</th>\n",
              "      <th>genre_ Shounen</th>\n",
              "      <th>...</th>\n",
              "      <th>genre_Action</th>\n",
              "      <th>genre_Adventure</th>\n",
              "      <th>genre_Cars</th>\n",
              "      <th>genre_Comedy</th>\n",
              "      <th>genre_Dementia</th>\n",
              "      <th>genre_Demons</th>\n",
              "      <th>genre_Drama</th>\n",
              "      <th>genre_Ecchi</th>\n",
              "      <th>genre_Fantasy</th>\n",
              "      <th>genre_Game</th>\n",
              "      <th>genre_Harem</th>\n",
              "      <th>genre_Hentai</th>\n",
              "      <th>genre_Historical</th>\n",
              "      <th>genre_Horror</th>\n",
              "      <th>genre_Josei</th>\n",
              "      <th>genre_Kids</th>\n",
              "      <th>genre_Magic</th>\n",
              "      <th>genre_Martial Arts</th>\n",
              "      <th>genre_Mecha</th>\n",
              "      <th>genre_Military</th>\n",
              "      <th>genre_Music</th>\n",
              "      <th>genre_Mystery</th>\n",
              "      <th>genre_Parody</th>\n",
              "      <th>genre_Police</th>\n",
              "      <th>genre_Psychological</th>\n",
              "      <th>genre_Romance</th>\n",
              "      <th>genre_Samurai</th>\n",
              "      <th>genre_School</th>\n",
              "      <th>genre_Sci-Fi</th>\n",
              "      <th>genre_Seinen</th>\n",
              "      <th>genre_Shoujo</th>\n",
              "      <th>genre_Shounen</th>\n",
              "      <th>genre_Slice of Life</th>\n",
              "      <th>genre_Space</th>\n",
              "      <th>genre_Sports</th>\n",
              "      <th>genre_Super Power</th>\n",
              "      <th>genre_Supernatural</th>\n",
              "      <th>genre_Thriller</th>\n",
              "      <th>genre_Vampire</th>\n",
              "      <th>genre_Yaoi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>200630</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>200630</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>200630</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>200630</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64</td>\n",
              "      <td>793665</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  episodes  members  type_Movie  ...  genre_Thriller  genre_Vampire  genre_Yaoi\n",
              "0        1   200630           1  ...               0              0           0\n",
              "1        1   200630           1  ...               0              0           0\n",
              "2        1   200630           1  ...               0              0           0\n",
              "3        1   200630           1  ...               0              0           0\n",
              "4       64   793665           0  ...               0              0           0\n",
              "\n",
              "[5 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_BVKtFdD0MB",
        "colab_type": "text"
      },
      "source": [
        "### Normalize Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "GuwXlRBlD0ME",
        "colab_type": "code",
        "outputId": "2e8db782-7ba4-4a3f-e1f2-56944e916cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "scaled_df = myNormalize(df_train)\n",
        "scaled_df.head()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197867</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197867</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197867</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197867</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.034673</td>\n",
              "      <td>0.782769</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1    2    3    4    5   ...   84   85   86   87   88   89\n",
              "0  0.000000  0.197867  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1  0.000000  0.197867  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2  0.000000  0.197867  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  0.000000  0.197867  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4  0.034673  0.782769  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 90 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPmXxGjED0ML",
        "colab_type": "text"
      },
      "source": [
        "### Using PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeBV07FG-CD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5870fe5b-a44d-4ba6-9bc1-8b3267dbbb9f"
      },
      "source": [
        "# https://towardsdatascience.com/an-approach-to-choosing-the-number-of-components-in-a-principal-component-analysis-pca-3b9f3d6e73fe\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#Fitting the PCA algorithm with our Data\n",
        "pca = PCA().fit(scaled_df)\n",
        "\n",
        "#Plotting the Cumulative Summation of the Explained Variance\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)') #for each component\n",
        "plt.title('Pulsar Dataset Explained Variance')\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nScE551yj/w/xC3wTWpvWAgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "wqsy0PEoD0MN",
        "colab_type": "code",
        "outputId": "667af5ad-5e4b-42cc-83f1-5e54d53bd586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "# Now we will choose 40 components so we can preserve something around 98.8% or 99% of the total variance of the data\n",
        "n_components=40\n",
        "pca_df = myPCA(scaled_df, n_components)\n",
        "pca_df.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.311566</td>\n",
              "      <td>0.786508</td>\n",
              "      <td>-0.420821</td>\n",
              "      <td>0.005236</td>\n",
              "      <td>-0.078664</td>\n",
              "      <td>-0.049645</td>\n",
              "      <td>-0.062636</td>\n",
              "      <td>0.007171</td>\n",
              "      <td>-0.075350</td>\n",
              "      <td>-0.030938</td>\n",
              "      <td>0.086265</td>\n",
              "      <td>-0.139423</td>\n",
              "      <td>-0.157023</td>\n",
              "      <td>0.028296</td>\n",
              "      <td>-0.081142</td>\n",
              "      <td>-0.232689</td>\n",
              "      <td>-0.299072</td>\n",
              "      <td>0.804718</td>\n",
              "      <td>-0.258789</td>\n",
              "      <td>-0.007697</td>\n",
              "      <td>-0.094831</td>\n",
              "      <td>-0.108057</td>\n",
              "      <td>-0.062478</td>\n",
              "      <td>0.025721</td>\n",
              "      <td>0.003367</td>\n",
              "      <td>-0.024992</td>\n",
              "      <td>-0.033515</td>\n",
              "      <td>-0.004893</td>\n",
              "      <td>-0.011738</td>\n",
              "      <td>-0.006790</td>\n",
              "      <td>-0.011768</td>\n",
              "      <td>-0.014487</td>\n",
              "      <td>0.009419</td>\n",
              "      <td>-0.010513</td>\n",
              "      <td>-0.008315</td>\n",
              "      <td>-0.004252</td>\n",
              "      <td>0.005403</td>\n",
              "      <td>-0.013755</td>\n",
              "      <td>-0.007030</td>\n",
              "      <td>-0.008421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.284842</td>\n",
              "      <td>0.763991</td>\n",
              "      <td>-0.412009</td>\n",
              "      <td>-0.010872</td>\n",
              "      <td>-0.110067</td>\n",
              "      <td>-0.087028</td>\n",
              "      <td>-0.096769</td>\n",
              "      <td>0.054629</td>\n",
              "      <td>-0.179466</td>\n",
              "      <td>-0.045545</td>\n",
              "      <td>0.764386</td>\n",
              "      <td>0.581467</td>\n",
              "      <td>0.033981</td>\n",
              "      <td>-0.066736</td>\n",
              "      <td>0.030945</td>\n",
              "      <td>0.068189</td>\n",
              "      <td>0.010380</td>\n",
              "      <td>-0.031950</td>\n",
              "      <td>-0.043618</td>\n",
              "      <td>0.008152</td>\n",
              "      <td>-0.027472</td>\n",
              "      <td>-0.040196</td>\n",
              "      <td>-0.033364</td>\n",
              "      <td>0.004752</td>\n",
              "      <td>0.006596</td>\n",
              "      <td>-0.016145</td>\n",
              "      <td>-0.028692</td>\n",
              "      <td>-0.009397</td>\n",
              "      <td>-0.005322</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>-0.007243</td>\n",
              "      <td>-0.012986</td>\n",
              "      <td>0.006305</td>\n",
              "      <td>-0.011367</td>\n",
              "      <td>-0.008385</td>\n",
              "      <td>-0.001485</td>\n",
              "      <td>0.008495</td>\n",
              "      <td>-0.013250</td>\n",
              "      <td>-0.008657</td>\n",
              "      <td>-0.008899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.284838</td>\n",
              "      <td>0.767910</td>\n",
              "      <td>-0.395570</td>\n",
              "      <td>-0.007614</td>\n",
              "      <td>-0.091869</td>\n",
              "      <td>-0.059765</td>\n",
              "      <td>-0.062085</td>\n",
              "      <td>0.036505</td>\n",
              "      <td>-0.086830</td>\n",
              "      <td>-0.024721</td>\n",
              "      <td>0.092181</td>\n",
              "      <td>-0.282590</td>\n",
              "      <td>-0.451934</td>\n",
              "      <td>-0.569129</td>\n",
              "      <td>0.527433</td>\n",
              "      <td>0.287048</td>\n",
              "      <td>0.035417</td>\n",
              "      <td>-0.060918</td>\n",
              "      <td>-0.105736</td>\n",
              "      <td>-0.014495</td>\n",
              "      <td>-0.031114</td>\n",
              "      <td>-0.062848</td>\n",
              "      <td>-0.045541</td>\n",
              "      <td>0.012584</td>\n",
              "      <td>0.004916</td>\n",
              "      <td>-0.021748</td>\n",
              "      <td>-0.033715</td>\n",
              "      <td>-0.011331</td>\n",
              "      <td>-0.009085</td>\n",
              "      <td>-0.006173</td>\n",
              "      <td>-0.009486</td>\n",
              "      <td>-0.014693</td>\n",
              "      <td>0.006516</td>\n",
              "      <td>-0.012742</td>\n",
              "      <td>-0.010013</td>\n",
              "      <td>-0.005441</td>\n",
              "      <td>0.006632</td>\n",
              "      <td>-0.015216</td>\n",
              "      <td>-0.013255</td>\n",
              "      <td>-0.008828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.291600</td>\n",
              "      <td>0.777175</td>\n",
              "      <td>-0.408316</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>-0.080828</td>\n",
              "      <td>-0.049799</td>\n",
              "      <td>-0.056889</td>\n",
              "      <td>0.019143</td>\n",
              "      <td>-0.070776</td>\n",
              "      <td>-0.027970</td>\n",
              "      <td>0.078032</td>\n",
              "      <td>-0.143403</td>\n",
              "      <td>-0.122692</td>\n",
              "      <td>-0.013062</td>\n",
              "      <td>-0.109524</td>\n",
              "      <td>-0.389583</td>\n",
              "      <td>-0.602805</td>\n",
              "      <td>-0.563640</td>\n",
              "      <td>-0.290751</td>\n",
              "      <td>-0.050590</td>\n",
              "      <td>-0.053021</td>\n",
              "      <td>-0.099435</td>\n",
              "      <td>-0.061857</td>\n",
              "      <td>0.024389</td>\n",
              "      <td>0.000886</td>\n",
              "      <td>-0.027275</td>\n",
              "      <td>-0.035598</td>\n",
              "      <td>-0.010717</td>\n",
              "      <td>-0.013599</td>\n",
              "      <td>-0.007701</td>\n",
              "      <td>-0.012264</td>\n",
              "      <td>-0.015394</td>\n",
              "      <td>0.007571</td>\n",
              "      <td>-0.011313</td>\n",
              "      <td>-0.009470</td>\n",
              "      <td>-0.007907</td>\n",
              "      <td>0.004373</td>\n",
              "      <td>-0.014810</td>\n",
              "      <td>-0.012184</td>\n",
              "      <td>-0.010701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.732145</td>\n",
              "      <td>-0.153155</td>\n",
              "      <td>-0.102203</td>\n",
              "      <td>-0.458230</td>\n",
              "      <td>0.816867</td>\n",
              "      <td>0.046173</td>\n",
              "      <td>0.015773</td>\n",
              "      <td>-0.064780</td>\n",
              "      <td>0.014353</td>\n",
              "      <td>-0.005004</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>0.017521</td>\n",
              "      <td>-0.007153</td>\n",
              "      <td>0.008121</td>\n",
              "      <td>0.015717</td>\n",
              "      <td>-0.003245</td>\n",
              "      <td>-0.012142</td>\n",
              "      <td>-0.006513</td>\n",
              "      <td>-0.013980</td>\n",
              "      <td>0.005161</td>\n",
              "      <td>-0.027947</td>\n",
              "      <td>-0.018716</td>\n",
              "      <td>-0.009781</td>\n",
              "      <td>-0.001060</td>\n",
              "      <td>0.018608</td>\n",
              "      <td>0.005430</td>\n",
              "      <td>-0.018090</td>\n",
              "      <td>0.010385</td>\n",
              "      <td>0.021625</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.006784</td>\n",
              "      <td>-0.013086</td>\n",
              "      <td>0.019780</td>\n",
              "      <td>-0.014676</td>\n",
              "      <td>-0.007435</td>\n",
              "      <td>0.026708</td>\n",
              "      <td>0.025910</td>\n",
              "      <td>-0.021044</td>\n",
              "      <td>-0.002562</td>\n",
              "      <td>0.044791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        37        38        39\n",
              "0 -0.311566  0.786508 -0.420821  ... -0.013755 -0.007030 -0.008421\n",
              "1 -0.284842  0.763991 -0.412009  ... -0.013250 -0.008657 -0.008899\n",
              "2 -0.284838  0.767910 -0.395570  ... -0.015216 -0.013255 -0.008828\n",
              "3 -0.291600  0.777175 -0.408316  ... -0.014810 -0.012184 -0.010701\n",
              "4  0.732145 -0.153155 -0.102203  ... -0.021044 -0.002562  0.044791\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "QRmzF6bED0MS",
        "colab_type": "text"
      },
      "source": [
        "### Splitting data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "aV2cjYqLD0MT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_df, df_test, test_size=0.3, random_state=109)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "vzrkLEh3D0MY",
        "colab_type": "text"
      },
      "source": [
        "### Generating model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "13JIAiCLD0Ma",
        "colab_type": "code",
        "outputId": "113a14d4-8604-40f7-8bb4-bd19cd5a957a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#Import MLP model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Create a MLP Classifier with PCA data\n",
        "clf = MLPClassifier(max_iter=500)\n",
        "\n",
        "# Train the model using the training sets\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
              "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "              validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4oB0rwfZD0Mk",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qOeFm64GD0Mm",
        "colab_type": "code",
        "outputId": "9eebee5c-a67c-4f7e-f13b-b224262cc1e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "# Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Predict with PCA data:\")\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Classification report: \")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict with PCA data:\n",
            "Accuracy:  0.723889783164473\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.54      0.58      3748\n",
            "           1       0.76      0.83      0.79      6813\n",
            "\n",
            "    accuracy                           0.72     10561\n",
            "   macro avg       0.70      0.68      0.69     10561\n",
            "weighted avg       0.72      0.72      0.72     10561\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmS7pmCxC0K_",
        "colab_type": "code",
        "outputId": "e7824c07-b74f-4d5a-a510-d217ada70357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Compute the accuracy score for all the cross validation folds.\n",
        "scores = model_selection.cross_val_score(clf, X_test, y_test, cv=5)\n",
        "scores\n",
        "# Take the mean of the scores (because we have one for each fold)\n",
        "print(\"Accuracy and the 95% confidence interval of the estimate are: {0:.3f} (+/- {0:.2f})\".format(scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy and the 95% confidence interval of the estimate are: 0.702 (+/- 0.70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZD1ORhjC7CU",
        "colab_type": "text"
      },
      "source": [
        "### Model Tuning with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5K0eRAYDDZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
        "#     'activation': ['tanh', 'relu'],\n",
        "#     'solver': ['lbfgs', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "#     'learning_rate': ['constant','adaptive']\n",
        "} \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gla2qD5nDG6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = GridSearchCV(clf, param_grid, refit=True, verbose=3, scoring=\"accuracy\", n_jobs=1, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur9KM9JvDHxA",
        "colab_type": "code",
        "outputId": "2429523e-48a6-4870-a2bc-b083fddd905a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 50, 50) ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 50, 50), score=0.717, total= 1.9min\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 50, 50) ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 50, 50), score=0.714, total= 2.3min\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 50, 50) ...................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 50, 50), score=0.731, total= 1.8min\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 50, 50) ...................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 50, 50), score=0.730, total= 2.0min\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 50, 50) ...................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 50, 50), score=0.722, total= 1.0min\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 100, 50) ..................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 100, 50), score=0.707, total= 1.2min\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 100, 50) ..................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 100, 50), score=0.714, total=  42.6s\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 100, 50) ..................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 100, 50), score=0.721, total=  58.2s\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 100, 50) ..................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 100, 50), score=0.731, total= 1.0min\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(50, 100, 50) ..................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(50, 100, 50), score=0.725, total= 1.2min\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(100,) .........................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(100,), score=0.711, total=  52.8s\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(100,) .........................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(100,), score=0.708, total=  45.5s\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(100,) .........................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(100,), score=0.720, total=  47.3s\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(100,) .........................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(100,), score=0.716, total=  38.1s\n",
            "[CV] alpha=0.0001, hidden_layer_sizes=(100,) .........................\n",
            "[CV]  alpha=0.0001, hidden_layer_sizes=(100,), score=0.724, total=  47.9s\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 50, 50) .....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 50, 50), score=0.695, total= 1.2min\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 50, 50) .....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 50, 50), score=0.692, total=  17.6s\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 50, 50) .....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 50, 50), score=0.714, total= 3.0min\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 50, 50) .....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 50, 50), score=0.702, total= 1.5min\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 50, 50) .....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 50, 50), score=0.710, total= 1.5min\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 100, 50) ....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 100, 50), score=0.700, total=  18.9s\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 100, 50) ....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 100, 50), score=0.700, total= 2.5min\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 100, 50) ....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 100, 50), score=0.715, total= 4.1min\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 100, 50) ....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 100, 50), score=0.719, total= 4.4min\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(50, 100, 50) ....................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(50, 100, 50), score=0.704, total=  19.7s\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(100,) ...........................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(100,), score=0.693, total=   7.7s\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(100,) ...........................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(100,), score=0.693, total=   7.3s\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(100,) ...........................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(100,), score=0.696, total=   7.5s\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(100,) ...........................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(100,), score=0.703, total=   6.8s\n",
            "[CV] alpha=0.05, hidden_layer_sizes=(100,) ...........................\n",
            "[CV]  alpha=0.05, hidden_layer_sizes=(100,), score=0.700, total=   7.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 37.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_iter=500,\n",
              "                                     momentum=0.9, n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=None, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='warn', n_jobs=1,\n",
              "             param_grid={'alpha': [0.0001, 0.05],\n",
              "                         'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n",
              "                                                (100,)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNYE7wPlDKkT",
        "colab_type": "code",
        "outputId": "2a35dc72-849f-4c06-c7b5-9f9a13610d41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(\"The best score is: {}\".format(grid.best_score_))\n",
        "print(\"The best estimator is: {}\".format(grid.best_estimator_))\n",
        "print(\"The best params is: {}\".format(grid.best_params_))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best score is: 0.7229301948051948\n",
            "The best estimator is: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=(50, 50, 50), learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
            "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
            "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
            "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
            "The best params is: {'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4utzACC0DMk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-run predictions with best model\n",
        "model = grid.best_estimator_\n",
        "grid_predictions = grid.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C94KtM3tDOdU",
        "colab_type": "code",
        "outputId": "fa88254b-5163-427e-fa14-6c9fc3d61126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Re-evaluate model\n",
        "print(\"With normalized data and the best estimator from Grid Search:\")\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, grid_predictions))\n",
        "print(\"Classification report: \")\n",
        "print(classification_report(y_test, grid_predictions))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With normalized data and the best estimator from Grid Search:\n",
            "Accuracy:  0.7126219108039011\n",
            "Classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.49      0.55      3748\n",
            "           1       0.75      0.84      0.79      6813\n",
            "\n",
            "    accuracy                           0.71     10561\n",
            "   macro avg       0.68      0.66      0.67     10561\n",
            "weighted avg       0.70      0.71      0.70     10561\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JDrVVpi9Ps0",
        "colab_type": "text"
      },
      "source": [
        "### AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVlsbEeaDQhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "7eb2aff2-153d-4841-dfb3-de9316607723"
      },
      "source": [
        "from yellowbrick.classifier import ROCAUC\n",
        "\n",
        "# Instantiate the visualizer with the classification model\n",
        "visualizer = ROCAUC(model, micro=False, macro=False, per_class=True)\n",
        "\n",
        "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
        "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "visualizer.poof()             # Draw/show/poof the data"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFnCAYAAABU0WtaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wOJ5N2Th5/I0wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1X_xsM09bvF",
        "colab_type": "text"
      },
      "source": [
        "### Validation Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yU9mr829f7N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3d1f0e1-9ec4-429f-d206-0f0fe1916308"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from yellowbrick.model_selection import ValidationCurve\n",
        "\n",
        "# Create the validation curve visualizer\n",
        "cv = StratifiedKFold(12)\n",
        "\n",
        "param_range = np.arange(100, 5000, 100)\n",
        "\n",
        "v_viz = ValidationCurve(\n",
        "    clf, param_name=\"max_iter\", param_range=param_range,\n",
        "    cv=cv, scoring=\"accuracy\", n_jobs=1\n",
        ")\n",
        "\n",
        "v_viz.fit(X_train, y_train)\n",
        "v_viz.poof()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1LpLhGJ9iuJ",
        "colab_type": "text"
      },
      "source": [
        "### Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwv94BK09hUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from yellowbrick.model_selection import LearningCurve\n",
        "\n",
        "\n",
        "l_viz = LearningCurve(\n",
        "    clf, cv=cv,\n",
        "    scoring='accuracy', n_jobs=1\n",
        ")\n",
        "\n",
        "# Fit and poof the visualizer\n",
        "l_viz.fit(X_train, y_train)\n",
        "l_viz.poof()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}