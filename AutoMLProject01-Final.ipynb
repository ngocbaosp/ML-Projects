{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoMLProject01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngocbaosp/ML-Projects/blob/master/AutoMLProject01-Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StxbZGOO2y3I",
        "colab_type": "text"
      },
      "source": [
        "# Install AutoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BisgUVyh-3x",
        "colab_type": "code",
        "outputId": "64cd6770-6a26-4223-b5c5-c2b512cdc5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "!apt-get install swig -y\n",
        "!pip install Cython numpy\n",
        "\n",
        "# sometimes you have to run the next command twice on colab\n",
        "# I haven't figured out why\n",
        "!pip install auto-sklearn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "swig is already the newest version (3.0.12-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n",
            "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.13.2)\n",
            "Requirement already satisfied: smac==0.8 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.8.0)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.4.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: pynisher>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.5.0)\n",
            "Requirement already satisfied: pyrfr<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.4)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29.12)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.2)\n",
            "Requirement already satisfied: xgboost>=0.80 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.90)\n",
            "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.24.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (41.0.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (3.7.4)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (0.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.12.0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.8.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2->auto-sklearn) (0.14)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.1.3)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (19.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.9.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.7.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.21.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (0.7.12)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac==0.8->auto-sklearn) (1.1.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2019.6.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Z7JRDni3Ms",
        "colab_type": "code",
        "outputId": "db86cb41-1804-4c50-bb2d-340a4c04ae03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "!pip install auto-sklearn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: auto-sklearn in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pynisher>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.5.0)\n",
            "Requirement already satisfied: pyrfr<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.4)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29.12)\n",
            "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.2)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.13.2)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: xgboost>=0.80 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.90)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (41.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.24.2)\n",
            "Requirement already satisfied: smac==0.8 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.8.0)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.4.10)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.2->auto-sklearn) (0.14)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2018.9)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.8.5)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (0.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (1.12.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from smac==0.8->auto-sklearn) (3.7.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.1.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (19.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (0.7.12)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.10.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.1.2)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (1.9.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.21.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac==0.8->auto-sklearn) (2.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac==0.8->auto-sklearn) (1.1.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac==0.8->auto-sklearn) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE4j6toFjO",
        "colab_type": "code",
        "outputId": "24093ac6-33d0-4d25-8c91-29fd74351e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import autosklearn.classification\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
            "  from numpy.core.umath_tests import inner1d\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GjDTVskomp1",
        "colab_type": "text"
      },
      "source": [
        "# AutoML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eWSIgFWo8O2",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a59x2kHcpQv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXK2-zGSpCxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% md\n",
        "#### MyPCA\n",
        "#%%\n",
        "def myPCA(data,n):\n",
        "    pca = PCA(n_components=n)\n",
        "    pca.fit(data)\n",
        "    df = pca.transform(data)\n",
        "    PCA_Data = pd.DataFrame(df)\n",
        "    return PCA_Data\n",
        "\n",
        "#%% md\n",
        "#### myNormalize\n",
        "#%%\n",
        "def myNormalize(data):\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    Normalized_Data = min_max_scaler.fit_transform(data)\n",
        "    Normalized_Data = pd.DataFrame(Normalized_Data)\n",
        "    return Normalized_Data\n",
        "\n",
        "#%% md\n",
        "#### myEncode\n",
        "#%%\n",
        "def myEncode(data,col): \n",
        "    NewData_Encode = data.copy()\n",
        "    NewData_Encode = pd.get_dummies(NewData_Encode, columns=col, prefix = col)\n",
        "    return NewData_Encode\n",
        "\n",
        "\n",
        "#%% md\n",
        "#### myCleanAndTransformData\n",
        "#%%\n",
        "def myCleanAndTransformData(data):\n",
        "    \n",
        "    #Drop null rows\n",
        "    NewData = data.dropna()\n",
        "    #Remove unknown ata\n",
        "    NewData = NewData[NewData['episodes']!='Unknown']\n",
        "    #Add a new column rating class \n",
        "    NewData['Class']=1\n",
        "    # 1: High\n",
        "    # or 0: Low based on rating\n",
        "    NewData.loc[NewData['rating'] >= NewData['rating'].mean(), 'Class'] = 1\n",
        "    NewData.loc[NewData['rating'] < NewData['rating'].mean(), 'Class'] = 0\n",
        "    \n",
        "    #Split genre values into rows\n",
        "    NewData = pd.DataFrame(NewData.genre.str.split(',').tolist(), index=[NewData.anime_id,NewData.type,NewData.episodes,NewData.rating,NewData.members,NewData.Class]).stack()\n",
        "    NewData = NewData.reset_index([0,'anime_id','type','episodes','rating','members','Class'])\n",
        "    NewData.columns=['anime_id','type','episodes','rating','members','Class','genre']\n",
        "    \n",
        "    #Encode type feature: 6 unique values\n",
        "    NewData = myEncode(NewData,['type'])\n",
        " \n",
        "    #Encode genre feature: 82 unique values\n",
        "    NewData = myEncode(NewData,['genre'])\n",
        " \n",
        "     #Drop anmie_id,rating,Class\n",
        "    NewData = NewData.drop(['rating'],axis=1)\n",
        "    NewData = NewData.drop(columns=['anime_id'])\n",
        "    #NewData = NewData.drop(columns=['episodes'])  \n",
        "    \n",
        "    return NewData\n",
        "\n",
        "\n",
        "#%% md\n",
        "#### mySplitData\n",
        "#%%\n",
        "def mySplitData(X_Data,Y_Data,test_size,random_state):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_Data, Y_Data, test_size=test_size, random_state=random_state)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def mySplitDataByTrainSize(X_Data,Y_Data,train_size,random_state):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_Data, Y_Data, train_size=train_size, random_state=random_state)\n",
        "    X_train, X_test, y_train, y_test = mySplitData(X_train,y_train,0.33,random_state)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWwslp1EpaUW",
        "colab_type": "code",
        "outputId": "db87ef0f-d1ab-4e36-96e0-8bcdcc3d44d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#%% md\n",
        "# Load data from files\n",
        "#%%\n",
        "RawData = pd.read_csv('anime.csv')\n",
        "RawData.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anime_id</th>\n",
              "      <th>name</th>\n",
              "      <th>genre</th>\n",
              "      <th>type</th>\n",
              "      <th>episodes</th>\n",
              "      <th>rating</th>\n",
              "      <th>members</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32281</td>\n",
              "      <td>Kimi no Na wa.</td>\n",
              "      <td>Drama, Romance, School, Supernatural</td>\n",
              "      <td>Movie</td>\n",
              "      <td>1</td>\n",
              "      <td>9.37</td>\n",
              "      <td>200630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5114</td>\n",
              "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
              "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
              "      <td>TV</td>\n",
              "      <td>64</td>\n",
              "      <td>9.26</td>\n",
              "      <td>793665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28977</td>\n",
              "      <td>Gintama°</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>TV</td>\n",
              "      <td>51</td>\n",
              "      <td>9.25</td>\n",
              "      <td>114262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9253</td>\n",
              "      <td>Steins;Gate</td>\n",
              "      <td>Sci-Fi, Thriller</td>\n",
              "      <td>TV</td>\n",
              "      <td>24</td>\n",
              "      <td>9.17</td>\n",
              "      <td>673572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9969</td>\n",
              "      <td>Gintama&amp;#039;</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>TV</td>\n",
              "      <td>51</td>\n",
              "      <td>9.16</td>\n",
              "      <td>151266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   anime_id                              name  ... rating members\n",
              "0     32281                    Kimi no Na wa.  ...   9.37  200630\n",
              "1      5114  Fullmetal Alchemist: Brotherhood  ...   9.26  793665\n",
              "2     28977                          Gintama°  ...   9.25  114262\n",
              "3      9253                       Steins;Gate  ...   9.17  673572\n",
              "4      9969                     Gintama&#039;  ...   9.16  151266\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwC0YFqhptN3",
        "colab_type": "code",
        "outputId": "e7142a3f-ac7d-4c7e-e605-adaa9efd8c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "#%% md\n",
        "#### Clean and Transform Data\n",
        "#%%\n",
        "Cleaned_Data = myCleanAndTransformData(RawData)\n",
        "Y_Data = Cleaned_Data['Class']\n",
        "X_Data = Cleaned_Data.drop(columns=['Class'])\n",
        "\n",
        "#%% md\n",
        "#### Normalize  Data\n",
        "#%%\n",
        "Normalized_Data = myNormalize(X_Data)\n",
        "#%% md\n",
        "#### PCA\n",
        "#%%\n",
        "n_components=40\n",
        "PCA_Data = myPCA(Normalized_Data,n_components)\n",
        "PCA_Data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.311566</td>\n",
              "      <td>0.786508</td>\n",
              "      <td>-0.420821</td>\n",
              "      <td>0.005236</td>\n",
              "      <td>-0.078664</td>\n",
              "      <td>-0.049645</td>\n",
              "      <td>-0.062636</td>\n",
              "      <td>0.007171</td>\n",
              "      <td>-0.075350</td>\n",
              "      <td>-0.030938</td>\n",
              "      <td>0.086265</td>\n",
              "      <td>-0.139423</td>\n",
              "      <td>-0.157023</td>\n",
              "      <td>0.028296</td>\n",
              "      <td>-0.081142</td>\n",
              "      <td>-0.232689</td>\n",
              "      <td>-0.299072</td>\n",
              "      <td>0.804718</td>\n",
              "      <td>-0.258789</td>\n",
              "      <td>-0.007697</td>\n",
              "      <td>-0.094827</td>\n",
              "      <td>-0.108054</td>\n",
              "      <td>-0.062482</td>\n",
              "      <td>0.025710</td>\n",
              "      <td>0.003345</td>\n",
              "      <td>-0.024982</td>\n",
              "      <td>-0.033484</td>\n",
              "      <td>-0.004927</td>\n",
              "      <td>-0.011708</td>\n",
              "      <td>-0.006766</td>\n",
              "      <td>-0.011789</td>\n",
              "      <td>-0.014352</td>\n",
              "      <td>0.009456</td>\n",
              "      <td>-0.010511</td>\n",
              "      <td>-0.008306</td>\n",
              "      <td>-0.003907</td>\n",
              "      <td>0.005473</td>\n",
              "      <td>-0.013950</td>\n",
              "      <td>-0.006672</td>\n",
              "      <td>-0.005472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.284842</td>\n",
              "      <td>0.763991</td>\n",
              "      <td>-0.412009</td>\n",
              "      <td>-0.010872</td>\n",
              "      <td>-0.110067</td>\n",
              "      <td>-0.087028</td>\n",
              "      <td>-0.096769</td>\n",
              "      <td>0.054629</td>\n",
              "      <td>-0.179466</td>\n",
              "      <td>-0.045545</td>\n",
              "      <td>0.764386</td>\n",
              "      <td>0.581467</td>\n",
              "      <td>0.033980</td>\n",
              "      <td>-0.066736</td>\n",
              "      <td>0.030945</td>\n",
              "      <td>0.068189</td>\n",
              "      <td>0.010380</td>\n",
              "      <td>-0.031949</td>\n",
              "      <td>-0.043617</td>\n",
              "      <td>0.008152</td>\n",
              "      <td>-0.027468</td>\n",
              "      <td>-0.040192</td>\n",
              "      <td>-0.033368</td>\n",
              "      <td>0.004743</td>\n",
              "      <td>0.006577</td>\n",
              "      <td>-0.016136</td>\n",
              "      <td>-0.028665</td>\n",
              "      <td>-0.009426</td>\n",
              "      <td>-0.005297</td>\n",
              "      <td>-0.004070</td>\n",
              "      <td>-0.007261</td>\n",
              "      <td>-0.012869</td>\n",
              "      <td>0.006336</td>\n",
              "      <td>-0.011367</td>\n",
              "      <td>-0.008377</td>\n",
              "      <td>-0.001193</td>\n",
              "      <td>0.008558</td>\n",
              "      <td>-0.013429</td>\n",
              "      <td>-0.008346</td>\n",
              "      <td>-0.006490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.284838</td>\n",
              "      <td>0.767910</td>\n",
              "      <td>-0.395570</td>\n",
              "      <td>-0.007614</td>\n",
              "      <td>-0.091869</td>\n",
              "      <td>-0.059765</td>\n",
              "      <td>-0.062085</td>\n",
              "      <td>0.036505</td>\n",
              "      <td>-0.086830</td>\n",
              "      <td>-0.024721</td>\n",
              "      <td>0.092181</td>\n",
              "      <td>-0.282590</td>\n",
              "      <td>-0.451934</td>\n",
              "      <td>-0.569129</td>\n",
              "      <td>0.527433</td>\n",
              "      <td>0.287048</td>\n",
              "      <td>0.035417</td>\n",
              "      <td>-0.060917</td>\n",
              "      <td>-0.105735</td>\n",
              "      <td>-0.014495</td>\n",
              "      <td>-0.031111</td>\n",
              "      <td>-0.062844</td>\n",
              "      <td>-0.045544</td>\n",
              "      <td>0.012576</td>\n",
              "      <td>0.004897</td>\n",
              "      <td>-0.021739</td>\n",
              "      <td>-0.033688</td>\n",
              "      <td>-0.011360</td>\n",
              "      <td>-0.009060</td>\n",
              "      <td>-0.006153</td>\n",
              "      <td>-0.009504</td>\n",
              "      <td>-0.014576</td>\n",
              "      <td>0.006546</td>\n",
              "      <td>-0.012743</td>\n",
              "      <td>-0.010005</td>\n",
              "      <td>-0.005156</td>\n",
              "      <td>0.006695</td>\n",
              "      <td>-0.015398</td>\n",
              "      <td>-0.012940</td>\n",
              "      <td>-0.006419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.291600</td>\n",
              "      <td>0.777175</td>\n",
              "      <td>-0.408316</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>-0.080828</td>\n",
              "      <td>-0.049799</td>\n",
              "      <td>-0.056889</td>\n",
              "      <td>0.019143</td>\n",
              "      <td>-0.070776</td>\n",
              "      <td>-0.027970</td>\n",
              "      <td>0.078032</td>\n",
              "      <td>-0.143404</td>\n",
              "      <td>-0.122693</td>\n",
              "      <td>-0.013062</td>\n",
              "      <td>-0.109523</td>\n",
              "      <td>-0.389584</td>\n",
              "      <td>-0.602805</td>\n",
              "      <td>-0.563640</td>\n",
              "      <td>-0.290750</td>\n",
              "      <td>-0.050590</td>\n",
              "      <td>-0.053017</td>\n",
              "      <td>-0.099432</td>\n",
              "      <td>-0.061860</td>\n",
              "      <td>0.024380</td>\n",
              "      <td>0.000867</td>\n",
              "      <td>-0.027267</td>\n",
              "      <td>-0.035573</td>\n",
              "      <td>-0.010745</td>\n",
              "      <td>-0.013576</td>\n",
              "      <td>-0.007682</td>\n",
              "      <td>-0.012282</td>\n",
              "      <td>-0.015279</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>-0.011312</td>\n",
              "      <td>-0.009465</td>\n",
              "      <td>-0.007631</td>\n",
              "      <td>0.004434</td>\n",
              "      <td>-0.014988</td>\n",
              "      <td>-0.011909</td>\n",
              "      <td>-0.008382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.732145</td>\n",
              "      <td>-0.153155</td>\n",
              "      <td>-0.102203</td>\n",
              "      <td>-0.458230</td>\n",
              "      <td>0.816867</td>\n",
              "      <td>0.046174</td>\n",
              "      <td>0.015773</td>\n",
              "      <td>-0.064781</td>\n",
              "      <td>0.014353</td>\n",
              "      <td>-0.005003</td>\n",
              "      <td>0.000576</td>\n",
              "      <td>0.017521</td>\n",
              "      <td>-0.007153</td>\n",
              "      <td>0.008121</td>\n",
              "      <td>0.015718</td>\n",
              "      <td>-0.003247</td>\n",
              "      <td>-0.012143</td>\n",
              "      <td>-0.006512</td>\n",
              "      <td>-0.013977</td>\n",
              "      <td>0.005161</td>\n",
              "      <td>-0.027934</td>\n",
              "      <td>-0.018705</td>\n",
              "      <td>-0.009793</td>\n",
              "      <td>-0.001093</td>\n",
              "      <td>0.018532</td>\n",
              "      <td>0.005471</td>\n",
              "      <td>-0.017978</td>\n",
              "      <td>0.010262</td>\n",
              "      <td>0.021732</td>\n",
              "      <td>0.001318</td>\n",
              "      <td>0.006750</td>\n",
              "      <td>-0.012701</td>\n",
              "      <td>0.019904</td>\n",
              "      <td>-0.014668</td>\n",
              "      <td>-0.007358</td>\n",
              "      <td>0.027884</td>\n",
              "      <td>0.026121</td>\n",
              "      <td>-0.021419</td>\n",
              "      <td>-0.000735</td>\n",
              "      <td>0.056595</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        37        38        39\n",
              "0 -0.311566  0.786508 -0.420821  ... -0.013950 -0.006672 -0.005472\n",
              "1 -0.284842  0.763991 -0.412009  ... -0.013429 -0.008346 -0.006490\n",
              "2 -0.284838  0.767910 -0.395570  ... -0.015398 -0.012940 -0.006419\n",
              "3 -0.291600  0.777175 -0.408316  ... -0.014988 -0.011909 -0.008382\n",
              "4  0.732145 -0.153155 -0.102203  ... -0.021419 -0.000735  0.056595\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T50hJ8mq2AZ",
        "colab_type": "code",
        "outputId": "99243798-8b97-464a-d400-44a2afdb520c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#%% md\n",
        "####----------------------------------------------------------------\n",
        "#### Split  PCA_Data\n",
        "####----------------------------------------------------------------\n",
        "#%%\n",
        "PCA_X_train, PCA_X_test, PCA_y_train, PCA_y_test  = mySplitData(PCA_Data,Y_Data,0.33,42)\n",
        "\n",
        "PCA_X_train.head()\n",
        "#%%\n",
        "PCA_X_test.head()\n",
        "#%%\n",
        "PCA_y_train.head()\n",
        "#%%\n",
        "PCA_y_test.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22373    0\n",
              "10508    1\n",
              "11570    1\n",
              "22262    0\n",
              "734      1\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uesuJDbrHRU",
        "colab_type": "text"
      },
      "source": [
        "## **Train and Test Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nn4NvY4rM6D",
        "colab_type": "code",
        "outputId": "46838f94-76f5-4a15-e33b-c7fa7cb58e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# configure auto-sklearn\n",
        "anmie_automl = autosklearn.classification.AutoSklearnClassifier(\n",
        "          time_left_for_this_task=120, # run auto-sklearn for at most 2min\n",
        "          per_run_time_limit=30, # spend at most 30 sec for each model training\n",
        "          include_preprocessors=[\"no_preprocessing\"]\n",
        "          )\n",
        "\n",
        "# train model(s)\n",
        "anmie_automl.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "PCA_y_predicted = anmie_automl.predict(PCA_X_test)\n",
        "test_acc = accuracy_score(PCA_y_test, PCA_y_predicted)\n",
        "\n",
        "print(\"Test Accuracy score {0}\".format(test_acc))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2019-07-31 15:19:59,852:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:19:59,862:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:20:01,866:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:20:03,871:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:20:05,883:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:20:07,887:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "['/tmp/autosklearn_tmp_137_3202/.auto-sklearn/ensembles/1.0000000000.ensemble', '/tmp/autosklearn_tmp_137_3202/.auto-sklearn/ensembles/1.0000000001.ensemble', '/tmp/autosklearn_tmp_137_3202/.auto-sklearn/ensembles/1.0000000002.ensemble', '/tmp/autosklearn_tmp_137_3202/.auto-sklearn/ensembles/1.0000000003.ensemble', '/tmp/autosklearn_tmp_137_3202/.auto-sklearn/ensembles/1.0000000004.ensemble', '/tmp/autosklearn_tmp_137_3202/.auto-sklearn/ensembles/1.0000000005.ensemble']\n",
            "Test Accuracy score 0.804424550228114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEjZqYPpswxw",
        "colab_type": "text"
      },
      "source": [
        "## Inspecting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loIqJX6_iI02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46af6d55-2bda-4b8b-b148-e39daf5092cd"
      },
      "source": [
        "# evaluate\n",
        "from sklearn.metrics import accuracy_score\n",
        "PCA_y_predicted = anmie_automl.predict(PCA_X_test)\n",
        "test_acc = accuracy_score(PCA_y_test, PCA_y_predicted)\n",
        "\n",
        "print(\"Test Accuracy score {0}\".format(test_acc))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.804424550228114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47ATUCSls-cx",
        "colab_type": "code",
        "outputId": "273b57a4-515d-4bef-9d72-2d3efc29d4e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "anmie_automl.sprint_statistics()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'auto-sklearn results:\\n  Dataset name: 64b53ca9ba24ac1e45ad29eb0951a812\\n  Metric: accuracy\\n  Best validation score: 0.796608\\n  Number of target algorithm runs: 7\\n  Number of successful target algorithm runs: 5\\n  Number of crashed target algorithm runs: 0\\n  Number of target algorithms that exceeded the time limit: 2\\n  Number of target algorithms that exceeded the memory limit: 0\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW2h1ROVtCWT",
        "colab_type": "code",
        "outputId": "fef63a9f-fac8-4b9c-f440-1bb6ac0a7b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "anmie_automl.show_models()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[(0.820000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'normalize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5240592829918601, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 10, 'classifier:random_forest:min_samples_split': 16, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00012586572428922356},\\ndataset_properties={\\n  'task': 1,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.120000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'gradient_boosting', 'imputation:strategy': 'mean', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:gradient_boosting:criterion': 'mse', 'classifier:gradient_boosting:learning_rate': 0.051832615669195795, 'classifier:gradient_boosting:loss': 'deviance', 'classifier:gradient_boosting:max_depth': 6, 'classifier:gradient_boosting:max_features': 0.8807456180216267, 'classifier:gradient_boosting:max_leaf_nodes': 'None', 'classifier:gradient_boosting:min_impurity_decrease': 0.0, 'classifier:gradient_boosting:min_samples_leaf': 7, 'classifier:gradient_boosting:min_samples_split': 19, 'classifier:gradient_boosting:min_weight_fraction_leaf': 0.0, 'classifier:gradient_boosting:n_estimators': 366, 'classifier:gradient_boosting:subsample': 0.7314831276137047, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004},\\ndataset_properties={\\n  'task': 1,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'classification',\\n  'signed': False})),\\n(0.060000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'categorical_encoding:__choice__': 'one_hot_encoding', 'classifier:__choice__': 'random_forest', 'imputation:strategy': 'most_frequent', 'preprocessor:__choice__': 'no_preprocessing', 'rescaling:__choice__': 'standardize', 'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True', 'classifier:random_forest:bootstrap': 'True', 'classifier:random_forest:criterion': 'gini', 'classifier:random_forest:max_depth': 'None', 'classifier:random_forest:max_features': 0.5686453602598863, 'classifier:random_forest:max_leaf_nodes': 'None', 'classifier:random_forest:min_impurity_decrease': 0.0, 'classifier:random_forest:min_samples_leaf': 1, 'classifier:random_forest:min_samples_split': 2, 'classifier:random_forest:min_weight_fraction_leaf': 0.0, 'classifier:random_forest:n_estimators': 100, 'categorical_encoding:one_hot_encoding:minimum_fraction': 0.41094614430753584},\\ndataset_properties={\\n  'task': 1,\\n  'sparse': False,\\n  'multilabel': False,\\n  'multiclass': False,\\n  'target_type': 'classification',\\n  'signed': False})),\\n]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVYIHHlotGEB",
        "colab_type": "code",
        "outputId": "59efabca-62ad-430d-a359-1eda2369bd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "anmie_automl.cv_results_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 9.36614823,  7.68715644, 30.03748894, 11.33386064,  0.49103284,\n",
              "        29.3589673 , 18.02530432]),\n",
              " 'mean_test_score': array([0.75960427, 0.79660799, 0.        , 0.75767699, 0.6563022 ,\n",
              "        0.78350251, 0.        ]),\n",
              " 'param_balancing:strategy': masked_array(data=['none', 'none', 'none', 'weighting', 'weighting',\n",
              "                    'weighting', 'none'],\n",
              "              mask=[False, False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U9'),\n",
              " 'param_categorical_encoding:__choice__': masked_array(data=['one_hot_encoding', 'one_hot_encoding',\n",
              "                    'one_hot_encoding', 'one_hot_encoding',\n",
              "                    'one_hot_encoding', 'one_hot_encoding',\n",
              "                    'one_hot_encoding'],\n",
              "              mask=[False, False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U16'),\n",
              " 'param_categorical_encoding:one_hot_encoding:minimum_fraction': masked_array(data=[0.01, 0.00012586572428922356, --, 0.41094614430753584,\n",
              "                    0.00034835629696198427, 0.010000000000000004, --],\n",
              "              mask=[False, False,  True, False, False, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_categorical_encoding:one_hot_encoding:use_minimum_fraction': masked_array(data=['True', 'True', 'False', 'True', 'True', 'True',\n",
              "                    'False'],\n",
              "              mask=[False, False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U5'),\n",
              " 'param_classifier:__choice__': masked_array(data=['random_forest', 'random_forest', 'libsvm_svc',\n",
              "                    'random_forest', 'gaussian_nb', 'gradient_boosting',\n",
              "                    'random_forest'],\n",
              "              mask=[False, False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U17'),\n",
              " 'param_classifier:adaboost:algorithm': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:adaboost:learning_rate': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:adaboost:max_depth': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:adaboost:n_estimators': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:bernoulli_nb:alpha': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:bernoulli_nb:fit_prior': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:criterion': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:max_depth_factor': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:max_features': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:min_samples_split': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:decision_tree:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:bootstrap': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:criterion': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:max_depth': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:max_features': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:max_leaf_nodes': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:min_impurity_decrease': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:min_samples_split': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:extra_trees:n_estimators': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:gradient_boosting:criterion': masked_array(data=[--, --, --, --, --, 'mse', --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:gradient_boosting:learning_rate': masked_array(data=[--, --, --, --, --, 0.051832615669195795, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:loss': masked_array(data=[--, --, --, --, --, 'deviance', --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:gradient_boosting:max_depth': masked_array(data=[--, --, --, --, --, 6.0, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:max_features': masked_array(data=[--, --, --, --, --, 0.8807456180216267, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:max_leaf_nodes': masked_array(data=[--, --, --, --, --, 'None', --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:gradient_boosting:min_impurity_decrease': masked_array(data=[--, --, --, --, --, 0.0, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:min_samples_leaf': masked_array(data=[--, --, --, --, --, 7.0, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:min_samples_split': masked_array(data=[--, --, --, --, --, 19.0, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:min_weight_fraction_leaf': masked_array(data=[--, --, --, --, --, 0.0, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:n_estimators': masked_array(data=[--, --, --, --, --, 366.0, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:gradient_boosting:subsample': masked_array(data=[--, --, --, --, --, 0.7314831276137047, --],\n",
              "              mask=[ True,  True,  True,  True,  True, False,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:k_nearest_neighbors:n_neighbors': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:k_nearest_neighbors:p': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:k_nearest_neighbors:weights': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:lda:n_components': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:lda:shrinkage': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:lda:shrinkage_factor': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:lda:tol': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:C': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:dual': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:fit_intercept': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:intercept_scaling': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:loss': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:multi_class': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:penalty': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:liblinear_svc:tol': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:libsvm_svc:C': masked_array(data=[--, --, 6.342897164595882, --, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:libsvm_svc:coef0': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:libsvm_svc:degree': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:libsvm_svc:gamma': masked_array(data=[--, --, 0.2229870623330047, --, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:libsvm_svc:kernel': masked_array(data=[--, --, 'rbf', --, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:libsvm_svc:max_iter': masked_array(data=[--, --, -1.0, --, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:libsvm_svc:shrinking': masked_array(data=[--, --, 'False', --, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U32'),\n",
              " 'param_classifier:libsvm_svc:tol': masked_array(data=[--, --, 2.006345264381097e-05, --, --, --, --],\n",
              "              mask=[ True,  True, False,  True,  True,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:multinomial_nb:alpha': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:multinomial_nb:fit_prior': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:C': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:average': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:fit_intercept': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:loss': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:passive_aggressive:tol': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:qda:reg_param': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:random_forest:bootstrap': masked_array(data=['True', 'True', --, 'True', --, --, 'True'],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U4'),\n",
              " 'param_classifier:random_forest:criterion': masked_array(data=['gini', 'gini', --, 'gini', --, --, 'gini'],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U4'),\n",
              " 'param_classifier:random_forest:max_depth': masked_array(data=['None', 'None', --, 'None', --, --, 'None'],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U4'),\n",
              " 'param_classifier:random_forest:max_features': masked_array(data=[0.5, 0.5240592829918601, --, 0.5686453602598863, --,\n",
              "                    --, 0.9260795160807372],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:max_leaf_nodes': masked_array(data=['None', 'None', --, 'None', --, --, 'None'],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U4'),\n",
              " 'param_classifier:random_forest:min_impurity_decrease': masked_array(data=[0.0, 0.0, --, 0.0, --, --, 0.0],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:min_samples_leaf': masked_array(data=[1.0, 10.0, --, 1.0, --, --, 17.0],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:min_samples_split': masked_array(data=[2.0, 16.0, --, 2.0, --, --, 7.0],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:min_weight_fraction_leaf': masked_array(data=[0.0, 0.0, --, 0.0, --, --, 0.0],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:random_forest:n_estimators': masked_array(data=[100.0, 100.0, --, 100.0, --, --, 100.0],\n",
              "              mask=[False, False,  True, False,  True,  True, False],\n",
              "        fill_value=1e+20),\n",
              " 'param_classifier:sgd:alpha': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:average': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:epsilon': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:eta0': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:fit_intercept': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:l1_ratio': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:learning_rate': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:loss': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:penalty': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:power_t': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:sgd:tol': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:base_score': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:booster': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:colsample_bylevel': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:colsample_bytree': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:gamma': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:learning_rate': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:max_delta_step': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:max_depth': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:min_child_weight': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:n_estimators': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:normalize_type': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:rate_drop': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:reg_alpha': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:reg_lambda': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:sample_type': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:scale_pos_weight': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_classifier:xgradient_boosting:subsample': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_imputation:strategy': masked_array(data=['mean', 'mean', 'most_frequent', 'most_frequent',\n",
              "                    'mean', 'mean', 'mean'],\n",
              "              mask=[False, False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U13'),\n",
              " 'param_preprocessor:__choice__': masked_array(data=['no_preprocessing', 'no_preprocessing',\n",
              "                    'no_preprocessing', 'no_preprocessing',\n",
              "                    'no_preprocessing', 'no_preprocessing',\n",
              "                    'no_preprocessing'],\n",
              "              mask=[False, False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U16'),\n",
              " 'param_rescaling:__choice__': masked_array(data=['standardize', 'normalize', 'standardize',\n",
              "                    'standardize', 'robust_scaler', 'standardize',\n",
              "                    'minmax'],\n",
              "              mask=[False, False, False, False, False, False, False],\n",
              "        fill_value='N/A',\n",
              "             dtype='<U13'),\n",
              " 'param_rescaling:quantile_transformer:n_quantiles': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_rescaling:quantile_transformer:output_distribution': masked_array(data=[--, --, --, --, --, --, --],\n",
              "              mask=[ True,  True,  True,  True,  True,  True,  True],\n",
              "        fill_value=1e+20,\n",
              "             dtype=float64),\n",
              " 'param_rescaling:robust_scaler:q_max': masked_array(data=[--, --, --, --, 0.8245132980938538, --, --],\n",
              "              mask=[ True,  True,  True,  True, False,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'param_rescaling:robust_scaler:q_min': masked_array(data=[--, --, --, --, 0.08947420373097192, --, --],\n",
              "              mask=[ True,  True,  True,  True, False,  True,  True],\n",
              "        fill_value=1e+20),\n",
              " 'params': [{'balancing:strategy': 'none',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.01,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'random_forest',\n",
              "   'classifier:random_forest:bootstrap': 'True',\n",
              "   'classifier:random_forest:criterion': 'gini',\n",
              "   'classifier:random_forest:max_depth': 'None',\n",
              "   'classifier:random_forest:max_features': 0.5,\n",
              "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
              "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
              "   'classifier:random_forest:min_samples_leaf': 1,\n",
              "   'classifier:random_forest:min_samples_split': 2,\n",
              "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:random_forest:n_estimators': 100,\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'standardize'},\n",
              "  {'balancing:strategy': 'none',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00012586572428922356,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'random_forest',\n",
              "   'classifier:random_forest:bootstrap': 'True',\n",
              "   'classifier:random_forest:criterion': 'gini',\n",
              "   'classifier:random_forest:max_depth': 'None',\n",
              "   'classifier:random_forest:max_features': 0.5240592829918601,\n",
              "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
              "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
              "   'classifier:random_forest:min_samples_leaf': 10,\n",
              "   'classifier:random_forest:min_samples_split': 16,\n",
              "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:random_forest:n_estimators': 100,\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'normalize'},\n",
              "  {'balancing:strategy': 'none',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False',\n",
              "   'classifier:__choice__': 'libsvm_svc',\n",
              "   'classifier:libsvm_svc:C': 6.342897164595882,\n",
              "   'classifier:libsvm_svc:gamma': 0.2229870623330047,\n",
              "   'classifier:libsvm_svc:kernel': 'rbf',\n",
              "   'classifier:libsvm_svc:max_iter': -1,\n",
              "   'classifier:libsvm_svc:shrinking': 'False',\n",
              "   'classifier:libsvm_svc:tol': 2.006345264381097e-05,\n",
              "   'imputation:strategy': 'most_frequent',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'standardize'},\n",
              "  {'balancing:strategy': 'weighting',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.41094614430753584,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'random_forest',\n",
              "   'classifier:random_forest:bootstrap': 'True',\n",
              "   'classifier:random_forest:criterion': 'gini',\n",
              "   'classifier:random_forest:max_depth': 'None',\n",
              "   'classifier:random_forest:max_features': 0.5686453602598863,\n",
              "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
              "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
              "   'classifier:random_forest:min_samples_leaf': 1,\n",
              "   'classifier:random_forest:min_samples_split': 2,\n",
              "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:random_forest:n_estimators': 100,\n",
              "   'imputation:strategy': 'most_frequent',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'standardize'},\n",
              "  {'balancing:strategy': 'weighting',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.00034835629696198427,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'gaussian_nb',\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'robust_scaler',\n",
              "   'rescaling:robust_scaler:q_max': 0.8245132980938538,\n",
              "   'rescaling:robust_scaler:q_min': 0.08947420373097192},\n",
              "  {'balancing:strategy': 'weighting',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:minimum_fraction': 0.010000000000000004,\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'True',\n",
              "   'classifier:__choice__': 'gradient_boosting',\n",
              "   'classifier:gradient_boosting:criterion': 'mse',\n",
              "   'classifier:gradient_boosting:learning_rate': 0.051832615669195795,\n",
              "   'classifier:gradient_boosting:loss': 'deviance',\n",
              "   'classifier:gradient_boosting:max_depth': 6,\n",
              "   'classifier:gradient_boosting:max_features': 0.8807456180216267,\n",
              "   'classifier:gradient_boosting:max_leaf_nodes': 'None',\n",
              "   'classifier:gradient_boosting:min_impurity_decrease': 0.0,\n",
              "   'classifier:gradient_boosting:min_samples_leaf': 7,\n",
              "   'classifier:gradient_boosting:min_samples_split': 19,\n",
              "   'classifier:gradient_boosting:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:gradient_boosting:n_estimators': 366,\n",
              "   'classifier:gradient_boosting:subsample': 0.7314831276137047,\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'standardize'},\n",
              "  {'balancing:strategy': 'none',\n",
              "   'categorical_encoding:__choice__': 'one_hot_encoding',\n",
              "   'categorical_encoding:one_hot_encoding:use_minimum_fraction': 'False',\n",
              "   'classifier:__choice__': 'random_forest',\n",
              "   'classifier:random_forest:bootstrap': 'True',\n",
              "   'classifier:random_forest:criterion': 'gini',\n",
              "   'classifier:random_forest:max_depth': 'None',\n",
              "   'classifier:random_forest:max_features': 0.9260795160807372,\n",
              "   'classifier:random_forest:max_leaf_nodes': 'None',\n",
              "   'classifier:random_forest:min_impurity_decrease': 0.0,\n",
              "   'classifier:random_forest:min_samples_leaf': 17,\n",
              "   'classifier:random_forest:min_samples_split': 7,\n",
              "   'classifier:random_forest:min_weight_fraction_leaf': 0.0,\n",
              "   'classifier:random_forest:n_estimators': 100,\n",
              "   'imputation:strategy': 'mean',\n",
              "   'preprocessor:__choice__': 'no_preprocessing',\n",
              "   'rescaling:__choice__': 'minmax'}],\n",
              " 'rank_test_scores': array([3, 1, 6, 4, 5, 2, 6]),\n",
              " 'status': ['Success',\n",
              "  'Success',\n",
              "  'Timeout',\n",
              "  'Success',\n",
              "  'Success',\n",
              "  'Success',\n",
              "  'Timeout']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhpbbHnV3b3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0nlmBEQR6Nd",
        "colab_type": "text"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuHZbULXSTfD",
        "colab_type": "code",
        "outputId": "5b03a309-3854-4f5d-a9fd-f5fbd54d02d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=9)\n",
        "\n",
        "# train model(s)\n",
        "knn_m = knn.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "knn_test_acc = knn_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(knn_test_acc))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.797279848497891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZcFpZiIR87D",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HJiVRVCXvKN",
        "colab_type": "code",
        "outputId": "80e16914-6e4a-4ca2-a71d-161b1b72a3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "# Create a svm Classifier with PCA data\n",
        "svc = svm.SVC(C=1.0, gamma=0.1, kernel='rbf') # Linear Kernel\n",
        "\n",
        "# train model(s)\n",
        "svm_m = svc.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "svm_test_acc = svm_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(svm_test_acc))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.6980287509684083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WefgYsW4R_td",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmpigibbYm2Q",
        "colab_type": "code",
        "outputId": "13660a2a-0de9-401e-a881-2505e3b4876f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Import svm model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Create a DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=0,max_depth=30,min_samples_leaf=20)\n",
        "\n",
        "\n",
        "# train model(s)\n",
        "dt_m = dt.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "dt_test_acc = dt_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(dt_test_acc))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.7936644572609107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zntQsupZSB_O",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N_gyiFQaL-7",
        "colab_type": "code",
        "outputId": "708e6835-4161-4ca2-f13d-d948f8a2c7f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a Random Forest Classifier with original data\n",
        "rf = RandomForestClassifier(criterion ='gini', max_depth= 15, max_features= 'sqrt', min_samples_leaf=1, min_samples_split= 5, n_estimators= 300)\n",
        "\n",
        "\n",
        "# train model(s)\n",
        "rf_m = rf.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "rf_test_acc = rf_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(rf_test_acc))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.8053714384092279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eToqzWdTSFFB",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkdWo0y0h5PZ",
        "colab_type": "code",
        "outputId": "aade3891-8afe-4cbc-bffc-061e444ed5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Import svm model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Create a NN Classifier with PCA data\n",
        "nn = MLPClassifier(max_iter=500)\n",
        "\n",
        "# train model(s)\n",
        "nn_m = nn.fit(PCA_X_train, PCA_y_train)\n",
        "\n",
        "# evaluate\n",
        "nn_test_acc = nn_m.score(PCA_X_test,PCA_y_test)\n",
        "print(\"Test Accuracy score {0}\".format(nn_test_acc))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score 0.7021606266678144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z8eT3iobBY8",
        "colab_type": "text"
      },
      "source": [
        "# Comparison between all classifiers (including AutoML)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyllWO0npzLj",
        "colab_type": "code",
        "outputId": "53cfa337-71c4-42d7-cb1e-7c592a64ae92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import autosklearn.classification\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "\n",
        "def roc_auc_curve(model,X_train,Y_train,X_test,Y_test):\n",
        "  model.fit(X_train, Y_train)\n",
        "\n",
        "  dt_lm = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "  dt_lm.fit(X_test, Y_test)\n",
        "\n",
        "  y_pred_dt = model.predict_proba(X_test)[:, 1]\n",
        "  fpr_dt, tpr_dt, _ = roc_curve(Y_test, y_pred_dt)\n",
        "  roc_auc = auc(fpr_dt, tpr_dt)\n",
        "  \n",
        "  test_acc_score = model.score(X_test,Y_test)\n",
        "  \n",
        "  return fpr_dt, tpr_dt,roc_auc,test_acc_score\n",
        "\n",
        "# Create a DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=0,max_depth=30,min_samples_leaf=20)\n",
        "fpr_dt, tpr_dt,roc_auc,dt_test_acc_score = roc_auc_curve(clf,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
        "\n",
        "\n",
        "#KNN \n",
        "knn = KNeighborsClassifier(n_neighbors=9)\n",
        "knn_fpr, knn_tpr,knn_roc_auc,knn_test_acc_score = roc_auc_curve(knn,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
        "\n",
        "#Random Forest \n",
        "rf = RandomForestClassifier(criterion ='gini', max_depth= 15, max_features= 'sqrt', min_samples_leaf=1, min_samples_split= 5, n_estimators= 300)\n",
        "rf_fpr, rf_tpr,rf_roc_auc,rf_test_acc_score = roc_auc_curve(rf,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
        "\n",
        "#svm \n",
        "svmModel = svm.SVC(C=1.0, gamma=0.1, kernel='rbf',probability=True) # Linear Kernel\n",
        "svm_fpr, svm_tpr,svm_roc_auc,svm_test_acc_score = roc_auc_curve(svmModel,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
        "\n",
        "#NN \n",
        "nn = MLPClassifier(max_iter=500)\n",
        "nn_fpr, nn_tpr,nn_roc_auc,nn_test_acc_score = roc_auc_curve(nn,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
        "\n",
        "#AutoML \n",
        "AutoML = autosklearn.classification.AutoSklearnClassifier(\n",
        "          time_left_for_this_task=120, # run auto-sklearn for at most 2min\n",
        "          per_run_time_limit=30, # spend at most 30 sec for each model training\n",
        "          include_preprocessors=[\"no_preprocessing\"]\n",
        "          )\n",
        "AutoML_fpr, AutoML_tpr,AutoML_roc_auc,AutoML_test_acc_score = roc_auc_curve(AutoML,PCA_X_train,PCA_y_train,PCA_X_test,PCA_y_test)\n",
        "\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "\n",
        "plt.plot(fpr_dt, tpr_dt, label='ROC of DT (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot(knn_fpr, knn_tpr, label='ROC of KNN (AUC = %0.2f)' % knn_roc_auc)\n",
        "plt.plot(rf_fpr, rf_tpr, label='ROC of RF (AUC = %0.2f)' % rf_roc_auc)\n",
        "plt.plot(svm_fpr, svm_tpr, label='ROC of SVM (AUC = %0.2f)' % svm_roc_auc)\n",
        "plt.plot(nn_fpr, nn_tpr, label='ROC of NN (AUC = %0.2f)' % nn_roc_auc)\n",
        "plt.plot(AutoML_fpr, AutoML_tpr, label='ROC of AutoML (AUC = %0.2f)' % AutoML_roc_auc)\n",
        "\n",
        "\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2019-07-31 15:41:48,769:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:41:48,780:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:41:50,786:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:41:52,790:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:41:54,796:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n",
            "[WARNING] [2019-07-31 15:41:56,807:EnsembleBuilder(1):64b53ca9ba24ac1e45ad29eb0951a812] No models better than random - using Dummy Score!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "['/tmp/autosklearn_tmp_137_8872/.auto-sklearn/ensembles/1.0000000000.ensemble', '/tmp/autosklearn_tmp_137_8872/.auto-sklearn/ensembles/1.0000000001.ensemble', '/tmp/autosklearn_tmp_137_8872/.auto-sklearn/ensembles/1.0000000002.ensemble', '/tmp/autosklearn_tmp_137_8872/.auto-sklearn/ensembles/1.0000000003.ensemble', '/tmp/autosklearn_tmp_137_8872/.auto-sklearn/ensembles/1.0000000004.ensemble']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBZM6cr/dC9mAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09fx2BdRJh8",
        "colab_type": "text"
      },
      "source": [
        "# Testing Accuracy Scores of all classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bwAazSqRI1P",
        "colab_type": "code",
        "outputId": "5aa40c7d-a9b7-46e9-c3ed-f4bd06b760e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "scores = pd.DataFrame({\"score\":[dt_test_acc_score,\n",
        "                       knn_test_acc_score,\n",
        "                       rf_test_acc_score,\n",
        "                       svm_test_acc_score,\n",
        "                       nn_test_acc_score,\n",
        "                       AutoML_test_acc_score],\n",
        "                     \"name\":[\"dt_test_acc_score\",\n",
        "                       \"knn_test_acc_score\",\n",
        "                       \"rf_test_acc_score\",\n",
        "                       \"svm_test_acc_score\",\n",
        "                       \"nn_test_acc_score\",\n",
        "                       \"AutoML_test_acc_score\"]})\n",
        "scores.sort_values(by=['score'])\n",
        "scores"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.793664</td>\n",
              "      <td>dt_test_acc_score</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.797280</td>\n",
              "      <td>knn_test_acc_score</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.803908</td>\n",
              "      <td>rf_test_acc_score</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.698029</td>\n",
              "      <td>svm_test_acc_score</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.703366</td>\n",
              "      <td>nn_test_acc_score</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.804425</td>\n",
              "      <td>AutoML_test_acc_score</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      score                   name\n",
              "0  0.793664      dt_test_acc_score\n",
              "1  0.797280     knn_test_acc_score\n",
              "2  0.803908      rf_test_acc_score\n",
              "3  0.698029     svm_test_acc_score\n",
              "4  0.703366      nn_test_acc_score\n",
              "5  0.804425  AutoML_test_acc_score"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}